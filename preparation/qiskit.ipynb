{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vdspw/quantum/blob/main/preparation/qiskit.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4ae1f164-69bd-4a4c-84df-3e358ca4effa",
      "metadata": {
        "id": "4ae1f164-69bd-4a4c-84df-3e358ca4effa"
      },
      "source": [
        "(sec-qiskit)=\n",
        "# Qiskit\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d0209622-44f9-4eb8-b405-0253304bac53",
      "metadata": {
        "id": "d0209622-44f9-4eb8-b405-0253304bac53"
      },
      "source": [
        "Qiskit is an open-source software development kit (SDK) for quantum computation. It runs inside Python platform.\n",
        "\n",
        "QIskit provides a large set of tools for\n",
        "\n",
        "1. developing new quantum algorithms and exploring new idea\n",
        "2. constructing a quantum circuit and testing it by running simulation on a classical computer\n",
        "3. executing the circuit on a real quantum computer through IBM Quantum Experience.\n",
        "\n",
        "We will use QIskit for all these three important coding steps.\n",
        "\n",
        "You can find useful information about Qiskit including tutorials and API documentation at [qiskit.org](https://qiskit.org)."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fe98a13f-b092-4072-b15d-32eb5d00eff2",
      "metadata": {
        "id": "fe98a13f-b092-4072-b15d-32eb5d00eff2"
      },
      "source": [
        "## Installation\n",
        "\n",
        "It is a set of python libraries but not included in Anaconda.  We need to install them manually.\n",
        "\n",
        "```\n",
        "pip install qiskit\n",
        "pip install qiskit[visualization]\n",
        "```\n",
        "\n",
        "Since conda does not manage these packages, you must update the package when a new version becomes available.  To check the current version, run the following command in the anaconda terminal window.\n",
        "\n",
        "On MS Windows, use Anaconda Powershell Prompt.\n",
        "```\n",
        "pip list | select-string \"qiskit\"\n",
        "\n",
        "qiskit                            0.36.2\n",
        "qiskit-aer                        0.10.4\n",
        "qiskit-ibmq-provider              0.19.1\n",
        "qiskit-ignis                      0.7.1\n",
        "qiskit-terra                      0.20.2\n",
        "```\n",
        "\n",
        "On Linux\n",
        "```\n",
        "pip list | grep qiskit\n",
        "\n",
        "qiskit                            0.36.2\n",
        "qiskit-aer                        0.10.4\n",
        "qiskit-ibmq-provider              0.19.1\n",
        "qiskit-ignis                      0.7.1\n",
        "qiskit-terra                      0.20.2\n",
        "```\n",
        "\n",
        "To check if updates are available, the following command shows newer versions.\n",
        "\n",
        "```\n",
        "# On MS Windows\n",
        "pip list --outdated | select-string \"qiskit\"\n",
        "\n",
        "# On Linux\n",
        "pip list --outdated | grep qiskit\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7f5227b8-46a9-4dd6-b7d5-957710f6b776",
      "metadata": {
        "id": "7f5227b8-46a9-4dd6-b7d5-957710f6b776"
      },
      "source": [
        "## IBM Quantum Experience\n",
        "\n",
        "In order to take the full advantage of Qiskit, you must first create an IBM Quantum Experience account.  With IBMid, you can run Qiskit codes on real IBM quantum computers as well as on realistic simulations on your computer.  Go to\n",
        "[quantum-computing.ibm.com](https://quantum-computing.ibm.com/) and set up an account.\n",
        "Log in to your account and take a look at IBM Quantum Dashboard where you find many useful stuffs which we discuss in later chapters.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2f8c0a15-acaf-4000-af45-d8fee5aab367",
      "metadata": {
        "id": "2f8c0a15-acaf-4000-af45-d8fee5aab367"
      },
      "source": [
        "## API key\n",
        "\n",
        "Next, you need to obtain an API key and save it in a local computer.\n",
        "\n",
        "1. Log in to IBM Quantum Experience at [quantum-computing.ibm.com](https://quantum-computing.ibm.com/)\n",
        "2. Click the user icon at the upper-right corner.\n",
        "3. Click \"Account setting\".\n",
        "4. Click \"Generate new token\"\n",
        "5. Click copy icon at the right end of the token box.  Your token is copied to the clipboard.\n",
        "6. Open a text editor and paste the token.  Save it it to a temporary file so that you can copy the token at a later time if needed. Delete the file after the key is properly installed.\n",
        "7. Open an Anaconda terminal window.\n",
        "8. Start python and execute the following command at the python prompt:\n",
        "\n",
        "```\n",
        ">>> from qiskit import IBMQ\n",
        ">>> IBMQ.save_account('past your token here')\n",
        "```\n",
        "The token must be inside the single quotes.  Now, we verify if the token works.\n",
        "\n",
        "```\n",
        ">>> IBMQ.load_account()\n",
        "```\n",
        "You should get the following response:\n",
        "```\n",
        "<AccountProvider for IBMQ(hub='ibm-q', group='open', project='main')>\n",
        "```\n",
        "If it worked, delete the temporary file created at step 6.  Otherwise, something went wrong. Try step 8 again.  Make it sure that the whole key is pasted.\n",
        "\n",
        "If you work on multiple computers, you have to install the same API on each machine."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "83fbb1fc-2c4d-490d-8c08-b9dde51a83ce",
      "metadata": {
        "id": "83fbb1fc-2c4d-490d-8c08-b9dde51a83ce"
      },
      "source": [
        "## Using Qiskit\n",
        "\n",
        "Since Qiskit is a collection of python modules, we must import it to your code before using it.  The package is so large that importing the entire package is not a good idea. In this book, we use only a small portion of it.  As you move on, this book introduces some basic modules absolutely necessary for quantum computing and explains how to use them step by step."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ca6efafb-373b-4bfb-a3ad-86efe2983a13",
      "metadata": {
        "id": "ca6efafb-373b-4bfb-a3ad-86efe2983a13"
      },
      "source": [
        "## Suggested Reading\n",
        "\n",
        "As mentioned above, there are various online resources at [qiskit.org](https://qiskit.org) and [quantum-computing.ibm.com](https://quantum-computing.ibm.com/). In particular, the following online textbook is recommended.\n",
        "\n",
        "* [Learn Quantum Computation using Qiskit](https://qiskit.org/textbook/)\n",
        "\n",
        "In addition, the following paperback book is recommended.\n",
        "\n",
        "* H. Norl&eacute;n: [*Quantum Computing in Practice with Qiskit and IBM Quantum Experience*](https://www.packtpub.com/product/quantum-computing-in-practice-with-qiskit-and-ibm-quantum-experience/9781838828448) (Packt, 2020).\n",
        "Source codes can be obtained at [github](https://github.com/PacktPublishing/Quantum-Computing-in-Practice-with-Qiskit-and-IBM-Quantum-Experience)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7782e9a6-ad8e-4154-82bc-df28e376f0f5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 349
        },
        "id": "7782e9a6-ad8e-4154-82bc-df28e376f0f5",
        "outputId": "4171ce10-564d-43c0-ae2b-38d836c40eaf"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'qiskit'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-9849f423b75d>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mqiskit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjupyter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'qiskit_version_table'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'qiskit_copyright'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'qiskit'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "import qiskit.tools.jupyter\n",
        "%qiskit_version_table\n",
        "%qiskit_copyright"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install qutip -q\n",
        "!pip install qiskit -q\n",
        "!pip install qiskit[visualization] -q\n",
        "!pip install git+https://github.com/qiskit-community/qiskit-textbook.git#subdirectory=qiskit-textbook-src -q\n",
        "\n",
        "import numpy as np\n",
        "np.set_printoptions(precision=3, suppress=True)\n",
        "import qutip as qt\n",
        "from matplotlib import pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "import pandas as pd\n",
        "import sklearn as sk\n",
        "import qiskit as qk"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cTdi0mGQMZhk",
        "outputId": "34c2d1d1-37a6-4394-ef7e-7420a55f9359"
      },
      "id": "cTdi0mGQMZhk",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m30.1/30.1 MB\u001b[0m \u001b[31m65.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.5/6.5 MB\u001b[0m \u001b[31m74.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m58.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.5/49.5 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.7/49.7 MB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m109.0/109.0 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m162.6/162.6 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for pylatexenc (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m24.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for qiskit-textbook (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "712490f4-32fa-4415-ad28-7e8c5a88e281",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        },
        "id": "712490f4-32fa-4415-ad28-7e8c5a88e281",
        "outputId": "290f871d-725d-44aa-e07e-cb2c285430cb"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'qiskit_ibm_runtime'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-8b3191a41f1f>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mqiskit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquantum_info\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSparsePauliOp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mqiskit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspiler\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgenerate_preset_pass_manager\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mqiskit_ibm_runtime\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mEstimatorV2\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mEstimator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Create a new circuit with two qubits\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'qiskit_ibm_runtime'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "from qiskit import QuantumCircuit\n",
        "from qiskit.quantum_info import SparsePauliOp\n",
        "from qiskit.transpiler import generate_preset_pass_manager\n",
        "from qiskit_ibm_runtime import EstimatorV2 as Estimator\n",
        "\n",
        "# Create a new circuit with two qubits\n",
        "qc = QuantumCircuit(2)\n",
        "\n",
        "# Add a Hadamard gate to qubit 0\n",
        "qc.h(0)\n",
        "\n",
        "# Perform a controlled-X gate on qubit 1, controlled by qubit 0\n",
        "qc.cx(0, 1)\n",
        "\n",
        "# Return a drawing of the circuit using MatPlotLib (\"mpl\").\n",
        "# These guides are written by using Jupyter notebooks, which\n",
        "# display the output of the last line of each cell.\n",
        "# If you're running this in a script, use `print(qc.draw())` to\n",
        "# print a text drawing.\n",
        "qc.draw(\"mpl\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install qiskit_ibm_runtime"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xYaa2sr5NQ2Z",
        "outputId": "dcedaed2-70e4-4941-93d0-70cce1e35e0f"
      },
      "id": "xYaa2sr5NQ2Z",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting qiskit_ibm_runtime\n",
            "  Downloading qiskit_ibm_runtime-0.39.0-py3-none-any.whl.metadata (21 kB)\n",
            "Requirement already satisfied: requests>=2.19 in /usr/local/lib/python3.11/dist-packages (from qiskit_ibm_runtime) (2.32.3)\n",
            "Collecting requests-ntlm>=1.1.0 (from qiskit_ibm_runtime)\n",
            "  Downloading requests_ntlm-1.3.0-py3-none-any.whl.metadata (2.4 kB)\n",
            "Requirement already satisfied: numpy>=1.13 in /usr/local/lib/python3.11/dist-packages (from qiskit_ibm_runtime) (2.0.2)\n",
            "Requirement already satisfied: urllib3>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from qiskit_ibm_runtime) (2.4.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.0 in /usr/local/lib/python3.11/dist-packages (from qiskit_ibm_runtime) (2.9.0.post0)\n",
            "Collecting ibm-platform-services>=0.22.6 (from qiskit_ibm_runtime)\n",
            "  Downloading ibm_platform_services-0.66.0-py3-none-any.whl.metadata (9.0 kB)\n",
            "Requirement already satisfied: pydantic>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from qiskit_ibm_runtime) (2.11.4)\n",
            "Requirement already satisfied: qiskit>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from qiskit_ibm_runtime) (2.0.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from qiskit_ibm_runtime) (24.2)\n",
            "Collecting ibm_cloud_sdk_core<4.0.0,>=3.22.1 (from ibm-platform-services>=0.22.6->qiskit_ibm_runtime)\n",
            "  Downloading ibm_cloud_sdk_core-3.23.0-py3-none-any.whl.metadata (8.7 kB)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.5.0->qiskit_ibm_runtime) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.5.0->qiskit_ibm_runtime) (2.33.2)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.5.0->qiskit_ibm_runtime) (4.13.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.5.0->qiskit_ibm_runtime) (0.4.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.0->qiskit_ibm_runtime) (1.17.0)\n",
            "Requirement already satisfied: rustworkx>=0.15.0 in /usr/local/lib/python3.11/dist-packages (from qiskit>=1.4.1->qiskit_ibm_runtime) (0.16.0)\n",
            "Requirement already satisfied: scipy>=1.5 in /usr/local/lib/python3.11/dist-packages (from qiskit>=1.4.1->qiskit_ibm_runtime) (1.15.3)\n",
            "Requirement already satisfied: sympy>=1.3 in /usr/local/lib/python3.11/dist-packages (from qiskit>=1.4.1->qiskit_ibm_runtime) (1.13.1)\n",
            "Requirement already satisfied: dill>=0.3 in /usr/local/lib/python3.11/dist-packages (from qiskit>=1.4.1->qiskit_ibm_runtime) (0.3.7)\n",
            "Requirement already satisfied: stevedore>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from qiskit>=1.4.1->qiskit_ibm_runtime) (5.4.1)\n",
            "Requirement already satisfied: symengine<0.14,>=0.11 in /usr/local/lib/python3.11/dist-packages (from qiskit>=1.4.1->qiskit_ibm_runtime) (0.13.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19->qiskit_ibm_runtime) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19->qiskit_ibm_runtime) (3.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19->qiskit_ibm_runtime) (2025.4.26)\n",
            "Requirement already satisfied: cryptography>=1.3 in /usr/local/lib/python3.11/dist-packages (from requests-ntlm>=1.1.0->qiskit_ibm_runtime) (43.0.3)\n",
            "Collecting pyspnego>=0.4.0 (from requests-ntlm>=1.1.0->qiskit_ibm_runtime)\n",
            "  Downloading pyspnego-0.11.2-py3-none-any.whl.metadata (5.4 kB)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.11/dist-packages (from cryptography>=1.3->requests-ntlm>=1.1.0->qiskit_ibm_runtime) (1.17.1)\n",
            "Requirement already satisfied: PyJWT<3.0.0,>=2.8.0 in /usr/local/lib/python3.11/dist-packages (from ibm_cloud_sdk_core<4.0.0,>=3.22.1->ibm-platform-services>=0.22.6->qiskit_ibm_runtime) (2.10.1)\n",
            "Requirement already satisfied: pbr>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from stevedore>=3.0.0->qiskit>=1.4.1->qiskit_ibm_runtime) (6.1.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy>=1.3->qiskit>=1.4.1->qiskit_ibm_runtime) (1.3.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.12->cryptography>=1.3->requests-ntlm>=1.1.0->qiskit_ibm_runtime) (2.22)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from pbr>=2.0.0->stevedore>=3.0.0->qiskit>=1.4.1->qiskit_ibm_runtime) (75.2.0)\n",
            "Downloading qiskit_ibm_runtime-0.39.0-py3-none-any.whl (3.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m51.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ibm_platform_services-0.66.0-py3-none-any.whl (363 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.9/363.9 kB\u001b[0m \u001b[31m25.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading requests_ntlm-1.3.0-py3-none-any.whl (6.6 kB)\n",
            "Downloading ibm_cloud_sdk_core-3.23.0-py3-none-any.whl (69 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.5/69.5 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyspnego-0.11.2-py3-none-any.whl (130 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.5/130.5 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: ibm_cloud_sdk_core, pyspnego, ibm-platform-services, requests-ntlm, qiskit_ibm_runtime\n",
            "Successfully installed ibm-platform-services-0.66.0 ibm_cloud_sdk_core-3.23.0 pyspnego-0.11.2 qiskit_ibm_runtime-0.39.0 requests-ntlm-1.3.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from qiskit import QuantumCircuit\n",
        "from qiskit.quantum_info import SparsePauliOp\n",
        "from qiskit.transpiler import generate_preset_pass_manager\n",
        "# from qiskit_ibm_runtime import EstimatorV2 as Estimator\n",
        "\n",
        "# Create a new circuit with two qubits\n",
        "qc = QuantumCircuit(2)\n",
        "\n",
        "# Add a Hadamard gate to qubit 0\n",
        "qc.h(0)\n",
        "\n",
        "# Perform a controlled-X gate on qubit 1, controlled by qubit 0\n",
        "qc.cx(0, 1)\n",
        "\n",
        "# Return a drawing of the circuit using MatPlotLib (\"mpl\").\n",
        "# These guides are written by using Jupyter notebooks, which\n",
        "# display the output of the last line of each cell.\n",
        "# If you're running this in a script, use `print(qc.draw())` to\n",
        "# print a text drawing.\n",
        "qc.draw(\"mpl\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "id": "B-XQ7-FuNfZH",
        "outputId": "1324fd43-3607-4bd0-8bd0-015d9edf8ba8"
      },
      "id": "B-XQ7-FuNfZH",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Figure size 287.294x200.667 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from qiskit import QuantumCircuit\n",
        "from qiskit.quantum_info import Operator\n",
        "\n",
        "qc = QuantumCircuit(1)\n",
        "qc.h(0)\n",
        "\n",
        "# Print the unitary matrix of the circuit\n",
        "print(\"Hadamard matrix:\\n\", Operator(qc).data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zudwub1GSloE",
        "outputId": "422ca576-1e88-48ec-e4ae-6273bf3ab676"
      },
      "id": "zudwub1GSloE",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hadamard matrix:\n",
            " [[ 0.70710678+0.j  0.70710678+0.j]\n",
            " [ 0.70710678+0.j -0.70710678+0.j]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "H = np.array([[1, 1],\n",
        "              [1, -1]]) / np.sqrt(2)\n",
        "\n",
        "zero = np.array([1,0])\n",
        "state = H @ zero   # H|0>\n",
        "\n",
        "print(\"Statevector:\", state)\n",
        "\n",
        "# Probabilities = |amplitude|^2\n",
        "probs = np.abs(state)**2\n",
        "print(\"Magnitudes (probabilities):\", probs)"
      ],
      "metadata": {
        "id": "Pa4iK4_KTcKw",
        "outputId": "29444648-547f-4b27-b0b4-5970bd3d8327",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "Pa4iK4_KTcKw",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Statevector: [0.70710678 0.70710678]\n",
            "Magnitudes (probabilities): [0.5 0.5]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from qiskit import QuantumCircuit\n",
        "from qiskit.quantum_info import Statevector\n",
        "\n",
        "# Example: sum value from Verilog\n",
        "sum_value = 2516154446\n",
        "max_value = 4286639746   # scale factor (choose based on your design)\n",
        "\n",
        "# Normalize into amplitude\n",
        "a = sum_value / max_value\n",
        "b = np.sqrt(1 - a**2)   # ensure normalization\n",
        "\n",
        "# Build statevector\n",
        "state = np.array([a, b])\n",
        "\n",
        "print(\"Input statevector:\", state)\n",
        "\n",
        "# Apply Hadamard\n",
        "H = np.array([[1, 1],\n",
        "              [1, -1]]) / np.sqrt(2)\n",
        "\n",
        "output = H @ state\n",
        "print(\"After Hadamard:\", output)\n",
        "print(\"Probabilities:\", np.abs(output)**2)"
      ],
      "metadata": {
        "id": "SOcm9XgYbIKb",
        "outputId": "64f172b1-1aa2-42e4-f5ec-6c65a7369d23",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "SOcm9XgYbIKb",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input statevector: [0.58697595 0.80960437]\n",
            "After Hadamard: [ 0.98753141 -0.15742206]\n",
            "Probabilities: [0.97521829 0.02478171]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from qiskit import QuantumCircuit\n",
        "from qiskit.quantum_info import Statevector\n",
        "\n",
        "# Example: sum value from Verilog\n",
        "sum_value = 1024986496\n",
        "max_value = 4286639746   # scale factor (choose based on your design)\n",
        "\n",
        "# Normalize into amplitude\n",
        "a = sum_value / max_value\n",
        "b = np.sqrt(1 - a**2)   # ensure normalization\n",
        "\n",
        "# Build statevector\n",
        "state = np.array([a, b])\n",
        "\n",
        "print(\"Input statevector:\", state)\n",
        "\n",
        "# Apply Hadamard\n",
        "H = np.array([[1, 1],\n",
        "              [1, -1]]) / np.sqrt(2)\n",
        "\n",
        "output = H @ state\n",
        "print(\"After Hadamard:\", output)\n",
        "print(\"Probabilities:\", np.abs(output)**2)"
      ],
      "metadata": {
        "id": "I_qzWKembO7U",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "282394fd-e4f3-4340-a8ba-dcd05b9a9602"
      },
      "id": "I_qzWKembO7U",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input statevector: [0.23911188 0.97099202]\n",
            "After Hadamard: [ 0.85567268 -0.51751741]\n",
            "Probabilities: [0.73217573 0.26782427]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "sum_values = []\n",
        "# Updated pattern based on the content of sum.txt.\n",
        "# This pattern looks for lines starting with \"Time=\", followed by numbers and \", sum=\",\n",
        "# and then captures the number that follows.\n",
        "pat = re.compile(r'^Time=\\d+, sum=(\\d+)')\n",
        "\n",
        "infile = '/content/sum.txt' # Define the input file\n",
        "\n",
        "with open(infile, 'r', encoding='utf-8', errors='ignore') as f:\n",
        "    for line in f:\n",
        "        m = pat.search(line)\n",
        "        if m:\n",
        "            val = int(m.group(1))\n",
        "            sum_values.append(val)\n",
        "\n",
        "print(f\"Found {len(sum_values)} sums.\")\n",
        "print(\"First few:\", sum_values[:5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X90tU7KQ0xAW",
        "outputId": "c6c12d2d-7ae5-4e21-e83b-cae321545db2"
      },
      "id": "X90tU7KQ0xAW",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 108960 sums.\n",
            "First few: [1024986496, 688428800, 2179547136, 3406420224, 622776576]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "de629044",
        "outputId": "808e46f5-ad75-4fd2-e27e-77db62edd0c9"
      },
      "source": [
        "import numpy as np\n",
        "from qiskit import QuantumCircuit\n",
        "from qiskit.quantum_info import Statevector\n",
        "\n",
        "# Assuming max_value is defined from a previous cell or needs to be set here\n",
        "# max_value = 4286639746 # Uncomment and set this if not already defined\n",
        "\n",
        "print(f\"Processing {len(sum_values)} extracted sums:\")\n",
        "\n",
        "# Apply Hadamard to each sum value\n",
        "for i, sum_value in enumerate(sum_values):\n",
        "    # Normalize into amplitude\n",
        "    if max_value == 0:\n",
        "        print(f\"Skipping sum_value {sum_value} at index {i} due to max_value being 0.\")\n",
        "        continue\n",
        "\n",
        "    a = sum_value / max_value\n",
        "    # Ensure a is within the valid range [-1, 1] for normalization\n",
        "    if not -1 <= a <= 1:\n",
        "        print(f\"Skipping sum_value {sum_value} at index {i} due to invalid normalized amplitude: {a}\")\n",
        "        continue\n",
        "\n",
        "    b = np.sqrt(1 - a**2)   # ensure normalization\n",
        "\n",
        "    # Build statevector\n",
        "    state = np.array([a, b])\n",
        "\n",
        "    print(f\"\\nSum {i+1}: {sum_value}\")\n",
        "    print(\"  Input statevector:\", state)\n",
        "\n",
        "    # Apply Hadamard\n",
        "    H = np.array([[1, 1],\n",
        "                  [1, -1]]) / np.sqrt(2)\n",
        "\n",
        "    output = H @ state\n",
        "    print(\"  After Hadamard:\", output)\n",
        "    print(\"  Probabilities:\", np.abs(output)**2)"
      ],
      "id": "de629044",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing 0 extracted sums:\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import re\n",
        "\n",
        "# ===== Step 1: Upload your clean file =====\n",
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "infile = list(uploaded.keys())[0]\n",
        "\n",
        "# ===== Step 2: Read all sums =====\n",
        "sum_values = []\n",
        "with open(infile, \"r\") as f:\n",
        "    for line in f:\n",
        "        m = re.search(r'sum\\s*=\\s*([0-9]+)', line)\n",
        "        if m:\n",
        "            sum_values.append(int(m.group(1)))\n",
        "\n",
        "print(f\"Loaded {len(sum_values)} sum values.\")\n",
        "print(\"First few:\", sum_values[:5])\n",
        "\n",
        "# Check if sum_values is empty\n",
        "if not sum_values:\n",
        "    print(\"No sum values were extracted from the file. Please check the file content and the regex pattern.\")\n",
        "else:\n",
        "    # ===== Step 3: Define Hadamard =====\n",
        "    H = np.array([[1, 1],\n",
        "                  [1, -1]]) / np.sqrt(2)\n",
        "\n",
        "    # Choose normalization strategy\n",
        "    max_value = float(max(sum_values))  # scale relative to max in file\n",
        "    print(\"Normalization max_value =\", max_value)\n",
        "\n",
        "    def to_amplitudes(val, max_val):\n",
        "        a = val / max_val\n",
        "        a = max(-1.0, min(1.0, a))   # clamp to [-1, 1]\n",
        "        b = np.sqrt(max(0.0, 1 - a*a))\n",
        "        return np.array([a, b])\n",
        "\n",
        "    # ===== Step 4: Process each sum =====\n",
        "    results = []\n",
        "    for idx, sv in enumerate(sum_values):\n",
        "        state_in = to_amplitudes(sv, max_value)\n",
        "        state_out = H @ state_in\n",
        "        probs = np.abs(state_out)**2\n",
        "        results.append((idx, sv, state_in[0], state_in[1],\n",
        "                        state_out[0], state_out[1], probs[0], probs[1]))\n",
        "\n",
        "    print(\"Example result:\", results[0])\n",
        "\n",
        "    # ===== Step 5: Save results to file =====\n",
        "    outname = \"hadamard_outputs.txt\"\n",
        "    with open(outname, \"w\") as f:\n",
        "        for r in results:\n",
        "            f.write(f\"Index: {r[0]}, Sum={r[1]}\\n\")\n",
        "            f.write(f\" Input state: [a={r[2]:.6f}, b={r[3]:.6f}]\\n\")\n",
        "            f.write(f\" Output state: [out0={r[4]:.6f}, out1={r[5]:.6f}]\\n\")\n",
        "            f.write(f\" Probabilities: [p0={r[6]:.6f}, p1={r[7]:.6f}]\\n\")\n",
        "            f.write(\"-\" * 50 + \"\\n\")\n",
        "\n",
        "    print(\"Saved results to\", outname)\n",
        "    files.download(outname)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        },
        "id": "VXWwuWEy4Dxm",
        "outputId": "acd8757d-a648-43e2-ea3f-fb43f73dab9b"
      },
      "id": "VXWwuWEy4Dxm",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-aa00d5dd-e6a2-43b9-9a03-092bf51f530a\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-aa00d5dd-e6a2-43b9-9a03-092bf51f530a\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-430053455.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# ===== Step 1: Upload your clean file =====\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0muploaded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0minfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muploaded\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/files.py\u001b[0m in \u001b[0;36mupload\u001b[0;34m(target_dir)\u001b[0m\n\u001b[1;32m     70\u001b[0m   \"\"\"\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m   \u001b[0muploaded_files\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_upload_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmultiple\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m   \u001b[0;31m# Mapping from original filename to filename as saved locally.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m   \u001b[0mlocal_filenames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/files.py\u001b[0m in \u001b[0;36m_upload_files\u001b[0;34m(multiple)\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m   \u001b[0;31m# First result is always an indication that the file picker has completed.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 164\u001b[0;31m   result = _output.eval_js(\n\u001b[0m\u001b[1;32m    165\u001b[0m       'google.colab._files._uploadFiles(\"{input_id}\", \"{output_id}\")'.format(\n\u001b[1;32m    166\u001b[0m           \u001b[0minput_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_id\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/output/_js.py\u001b[0m in \u001b[0;36meval_js\u001b[0;34m(script, ignore_result, timeout_sec)\u001b[0m\n\u001b[1;32m     38\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mignore_result\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0m_message\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_read_next_input_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_NOT_READY\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m       \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.025\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m       \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     if (\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# ==== 1) Upload your file (one integer per line) ====\n",
        "from google.colab import files\n",
        "uploaded = files.upload()  # choose your file, e.g., \"sum_only.txt\"\n",
        "infile = list(uploaded.keys())[0]\n",
        "print(\"Using file:\", infile)\n",
        "\n",
        "# ==== 2) Read all sums (numbers only, one per line) ====\n",
        "sum_values = []\n",
        "with open(infile, \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
        "    for line in f:\n",
        "        s = line.strip()\n",
        "        if s:\n",
        "            # if negatives are possible, use int(s); for unsigned only, int(s) is fine too\n",
        "            sum_values.append(int(s))\n",
        "\n",
        "print(f\"Loaded {len(sum_values)} sum values.\")\n",
        "print(\"First few:\", sum_values[:5])\n",
        "\n",
        "# ==== 3) Define Hadamard and normalization strategy ====\n",
        "H = np.array([[1, 1],\n",
        "              [1, -1]], dtype=float) / np.sqrt(2.0)\n",
        "\n",
        "# Choose your scaling:\n",
        "USE_FIXED_SCALE = False            # set True to use a fixed number like your hardware max\n",
        "FIXED_MAX_VALUE = 4286639746.0     # <- put your known scale here if using fixed\n",
        "\n",
        "if USE_FIXED_SCALE:\n",
        "    max_value = float(FIXED_MAX_VALUE)\n",
        "else:\n",
        "    # data-driven scale: use the maximum absolute value seen\n",
        "    max_value = float(max(1, max(abs(v) for v in sum_values)))\n",
        "\n",
        "print(\"Normalization max_value =\", max_value)\n",
        "\n",
        "def to_amplitudes(val, max_val):\n",
        "    # Map to a in [-1, 1], then b = sqrt(1 - a^2) (clamped to avoid tiny negatives from rounding)\n",
        "    a = val / max_val\n",
        "    a = max(-1.0, min(1.0, a))\n",
        "    b = np.sqrt(max(0.0, 1.0 - a*a))\n",
        "    return np.array([a, b], dtype=float)\n",
        "\n",
        "# ==== 4) Process each sum value through Hadamard ====\n",
        "results = []\n",
        "for idx, sv in enumerate(sum_values):\n",
        "    state_in  = to_amplitudes(sv, max_value)    # [a, b]\n",
        "    state_out = H @ state_in                    # [out0, out1]\n",
        "    probs     = np.abs(state_out) ** 2          # [p0, p1]\n",
        "    results.append((idx, sv, state_in[0], state_in[1],\n",
        "                    state_out[0], state_out[1], probs[0], probs[1]))\n",
        "\n",
        "print(\"Example row:\\n(index, sum, a, b, out0, out1, p0, p1)\\n\",\n",
        "      results[0] if results else \"No data\")\n",
        "\n",
        "# ==== 5) Save detailed text log ====\n",
        "txt_name = \"hadamard_outputs_layer1.txt\"\n",
        "with open(txt_name, \"w\") as f:\n",
        "    for r in results:\n",
        "        f.write(f\"Index: {r[0]}, Sum={r[1]}\\n\")\n",
        "        f.write(f\" Input state: [a={r[2]:.10f}, b={r[3]:.10f}]\\n\")\n",
        "        f.write(f\" Output state: [out0={r[4]:.10f}, out1={r[5]:.10f}]\\n\")\n",
        "        f.write(f\" Probabilities: [p0={r[6]:.10f}, p1={r[7]:.10f}]\\n\")\n",
        "        f.write(\"-\" * 60 + \"\\n\")\n",
        "print(\"Saved:\", txt_name)"
      ],
      "metadata": {
        "id": "UviC0qtNvRVE",
        "outputId": "e8d4bdcc-4e1c-4187-9cac-8ef0a57547ff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231
        }
      },
      "id": "UviC0qtNvRVE",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-ccb28da4-16e4-4a98-8d68-beb9d623320f\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-ccb28da4-16e4-4a98-8d68-beb9d623320f\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving layer1_sums.txt to layer1_sums (1).txt\n",
            "Using file: layer1_sums (1).txt\n",
            "Loaded 59507 sum values.\n",
            "First few: [357098112, 4101187456, 323344384, 208738688, 3973137024]\n",
            "Normalization max_value = 4294908672.0\n",
            "Example row:\n",
            "(index, sum, a, b, out0, out1, p0, p1)\n",
            " (0, 357098112, np.float64(0.08314451814262001), np.float64(0.9965375000986323), np.float64(0.7634504766235671), np.float64(-0.6458663714292981), np.float64(0.5828566302567518), np.float64(0.4171433697432481))\n",
            "Saved: hadamard_outputs_layer1.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import struct\n",
        "import re\n",
        "\n",
        "def float_to_ieee754_binary(f):\n",
        "    # Convert float to IEEE 754 double-precision binary (64-bit, big-endian)\n",
        "    packed = struct.pack('>d', f)\n",
        "    return ''.join(format(byte, '08b') for byte in packed)\n",
        "\n",
        "def process_hadamard_data(input_file, output_file):\n",
        "    with open(input_file, 'r') as f:\n",
        "        lines = f.readlines()\n",
        "\n",
        "    data_entries = {}\n",
        "    current_index = None\n",
        "\n",
        "    # Regex to capture data based on line prefixes\n",
        "    index_pat = re.compile(r'^Index:\\s*(\\d+)')\n",
        "    sum_pat = re.compile(r'^\\s*Sum=(\\d+)')\n",
        "    output_pat = re.compile(r'^\\s*Output state:\\s*\\[out0=(.*?), out1=(.*?)\\]')\n",
        "\n",
        "    for line in lines:\n",
        "        index_match = index_pat.match(line)\n",
        "        if index_match:\n",
        "            current_index = int(index_match.group(1))\n",
        "            if current_index not in data_entries:\n",
        "                data_entries[current_index] = {'sum_val': None, 'out0': None, 'out1': None}\n",
        "            continue # Move to the next line\n",
        "\n",
        "        if current_index is not None:\n",
        "            sum_match = sum_pat.match(line)\n",
        "            if sum_match:\n",
        "                data_entries[current_index]['sum_val'] = int(sum_match.group(1))\n",
        "                continue\n",
        "\n",
        "            output_match = output_pat.match(line)\n",
        "            if output_match:\n",
        "                try:\n",
        "                    data_entries[current_index]['out0'] = float(output_match.group(1).strip())\n",
        "                    data_entries[current_index]['out1'] = float(output_match.group(2).strip())\n",
        "                except ValueError:\n",
        "                    print(f\"Warning: Could not parse float values for index {current_index} from line: {line.strip()}\")\n",
        "                continue\n",
        "\n",
        "    with open(output_file, 'w') as f:\n",
        "        sorted_indices = sorted(data_entries.keys())\n",
        "        for index in sorted_indices:\n",
        "            entry = data_entries[index]\n",
        "            # Assume sum_val is 0 if not found\n",
        "            sum_val = entry['sum_val'] if entry['sum_val'] is not None else 0\n",
        "            out0 = entry['out0']\n",
        "            out1 = entry['out1']\n",
        "\n",
        "            if out0 is not None and out1 is not None:\n",
        "                sum_hex = f\"0x{sum_val:08X}\"\n",
        "                sum_binary = f\"{sum_val:032b}\"\n",
        "                highest_output = out0 if abs(out0) >= abs(out1) else out1\n",
        "                highest_binary = float_to_ieee754_binary(highest_output)\n",
        "                f.write(f\"Index: {index}, Sum (Hex): {sum_hex}, Sum (Binary): {sum_binary}, Highest Output (Binary): {highest_binary}\\n\")\n",
        "            else:\n",
        "                print(f\"Warning: Skipping index {index} due to missing output state (out0: {out0}, out1: {out1}).\")\n",
        "\n",
        "\n",
        "# Example usage\n",
        "input_file = 'hadamard_outputs_layer1.txt'\n",
        "output_file = 'hadamard_full_layer1.mem'\n",
        "process_hadamard_data(input_file, output_file)"
      ],
      "metadata": {
        "id": "lE9KPBG95GF7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "outputId": "97f36012-aeec-4396-d7b0-dc1175a03e0f"
      },
      "id": "lE9KPBG95GF7",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'hadamard_outputs_layer1.txt'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1670485968.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0minput_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'hadamard_outputs_layer1.txt'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0moutput_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'hadamard_full_layer1.mem'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m \u001b[0mprocess_hadamard_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/tmp/ipython-input-1670485968.py\u001b[0m in \u001b[0;36mprocess_hadamard_data\u001b[0;34m(input_file, output_file)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mprocess_hadamard_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0mlines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadlines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'hadamard_outputs_layer1.txt'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import re\n",
        "from google.colab import files # Keep this import in case the user wants to revert or upload a different file later\n",
        "import struct\n",
        "import os # Import os module to check for file existence\n",
        "\n",
        "def float_to_ieee754_binary(f):\n",
        "    # Convert float to IEEE 754 double-precision binary (64-bit, big-endian)\n",
        "    packed = struct.pack('>d', f)\n",
        "    return ''.join(format(byte, '08b') for byte in packed)\n",
        "\n",
        "def to_amplitudes(val, max_val):\n",
        "    # Map to a in [-1, 1], then b = sqrt(1 - a^2) (clamped to avoid tiny negatives from rounding)\n",
        "    a = val / max_val\n",
        "    a = max(-1.0, min(1.0, a))\n",
        "    b = np.sqrt(max(0.0, 1.0 - a*a))\n",
        "    return np.array([a, b], dtype=float)\n",
        "\n",
        "def process_hadamard_file(input_filename):\n",
        "    # ==== 1) Use the specified input file ====\n",
        "    infile = input_filename\n",
        "    if not os.path.exists(infile):\n",
        "        print(f\"Error: File not found at {infile}\")\n",
        "        # Optional: Prompt user to upload if file not found\n",
        "        # print(\"Please upload the file:\")\n",
        "        # uploaded = files.upload()\n",
        "        # if not uploaded:\n",
        "        #     print(\"No file uploaded. Exiting.\")\n",
        "        #     return\n",
        "        # infile = list(uploaded.keys())[0]\n",
        "        return # Exit if the specified file doesn't exist\n",
        "\n",
        "    print(\"Using file:\", infile)\n",
        "\n",
        "    # ==== 2) Read all sums, extracting only the integer after \"sum=\" ====\n",
        "    sum_values = []\n",
        "    # Updated pattern to specifically capture the integer after \"sum=\"\n",
        "    pat = re.compile(r'sum\\s*=\\s*(\\d+)')\n",
        "    try:\n",
        "        with open(infile, \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
        "            for line in f:\n",
        "                m = pat.search(line)\n",
        "                if m:\n",
        "                    try:\n",
        "                        sum_values.append(int(m.group(1)))\n",
        "                    except ValueError:\n",
        "                        print(f\"Skipping line with non-integer sum value: {line.strip()}\")\n",
        "                # else:\n",
        "                    # print(f\"Skipping line with no sum found: {line.strip()}\") # Optional: uncomment to see skipped lines\n",
        "\n",
        "    except Exception as e: # Catch any exception during file reading/parsing\n",
        "        print(f\"Error reading or parsing file {infile}: {e}\")\n",
        "        return\n",
        "\n",
        "\n",
        "    if not sum_values:\n",
        "        print(\"No valid integer sum values were extracted from the file. Please check the file content and the regex pattern.\")\n",
        "        return\n",
        "\n",
        "    print(f\"Loaded {len(sum_values)} sum values.\")\n",
        "    print(\"First few:\", sum_values[:5])\n",
        "\n",
        "    # ==== 3) Define Hadamard and normalization strategy ====\n",
        "    H = np.array([[1, 1],\n",
        "                  [1, -1]], dtype=float) / np.sqrt(2.0)\n",
        "\n",
        "    # Choose your scaling:\n",
        "    USE_FIXED_SCALE = False            # set True to use a fixed number like your hardware max\n",
        "    FIXED_MAX_VALUE = 4286639746.0     # <- put your known scale here if using fixed\n",
        "\n",
        "    if USE_FIXED_SCALE:\n",
        "        max_value = float(FIXED_MAX_VALUE)\n",
        "    else:\n",
        "        # data-driven scale: use the maximum absolute value seen\n",
        "        max_value = float(max(1, max(abs(v) for v in sum_values))) # Use abs() in case of negative values\n",
        "\n",
        "    print(\"Normalization max_value =\", max_value)\n",
        "\n",
        "    # ==== 4) Process each sum value through Hadamard ====\n",
        "    results = []\n",
        "    for idx, sv in enumerate(sum_values):\n",
        "        state_in  = to_amplitudes(sv, max_value)    # [a, b]\n",
        "        state_out = H @ state_in                    # [out0, out1]\n",
        "        probs     = np.abs(state_out) ** 2          # [p0, p1]\n",
        "        results.append((idx, sv, state_in[0], state_in[1],\n",
        "                        state_out[0], state_out[1], probs[0], probs[1]))\n",
        "\n",
        "    if results:\n",
        "        print(\"Example row:\\n(index, sum, a, b, out0, out1, p0, p1)\\n\",\n",
        "              results[0])\n",
        "    else:\n",
        "        print(\"No results generated.\")\n",
        "\n",
        "\n",
        "    # ==== 5) Save detailed text log ====\n",
        "    txt_name = \"hadamard_outputs_layer1.txt\" # Consider making this output file name dynamic based on input\n",
        "    with open(txt_name, \"w\") as f:\n",
        "        for r in results:\n",
        "            f.write(f\"Index: {r[0]}, Sum={r[1]}\\n\")\n",
        "            f.write(f\" Input state: [a={r[2]:.10f}, b={r[3]:.10f}]\\n\")\n",
        "            f.write(f\" Output state: [out0={r[4]:.10f}, out1={r[5]:.10f}]\\n\")\n",
        "            f.write(f\" Probabilities: [p0={r[6]:.10f}, p1={r[7]:.10f}]\\n\")\n",
        "            f.write(\"-\" * 60 + \"\\n\")\n",
        "    print(\"Saved detailed output to:\", txt_name)\n",
        "\n",
        "    # ==== 6) Save binary output file ====\n",
        "    mem_name = \"hadamard_full_layer1.mem\" # Consider making this output file name dynamic based on input\n",
        "    with open(mem_name, \"w\") as f:\n",
        "        for r in results:\n",
        "            index, sum_val, a, b, out0, out1, p0, p1 = r\n",
        "            highest_output = out0 if abs(out0) >= abs(out1) else out1\n",
        "            highest_binary = float_to_ieee754_binary(highest_output)\n",
        "\n",
        "            # Format sum_val as 32-bit binary (padded with zeros)\n",
        "            sum_binary_32bit = f\"{sum_val:032b}\"\n",
        "\n",
        "            f.write(f\"Index: {index}, Sum (Binary 32bit): {sum_binary_32bit}, Highest Output (Binary 64bit): {highest_binary}\\n\")\n",
        "    print(\"Saved binary output to:\", mem_name)\n",
        "\n",
        "    # Optional: Download the generated files\n",
        "    try:\n",
        "        files.download(txt_name)\n",
        "        files.download(mem_name)\n",
        "    except Exception as e:\n",
        "        print(f\"Could not automatically download files: {e}\")\n",
        "\n",
        "\n",
        "# Run the process with the specified file\n",
        "process_hadamard_file('layer-4.txt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kKrMvjuGrXND",
        "outputId": "86fa229b-6374-4c50-c03f-ace04f66a10c"
      },
      "id": "kKrMvjuGrXND",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: File not found at layer-4.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a7f124f6",
        "outputId": "62ac81f3-5d07-4fb0-c33e-636de07b7edb"
      },
      "source": [
        "# Read and display the first few lines of the output file\n",
        "output_filename = 'hadamard_outputs_layer1.txt'\n",
        "try:\n",
        "    with open(output_filename, 'r') as f:\n",
        "        print(f\"Contents of {output_filename}:\")\n",
        "        # Display only the first 20 lines to avoid large output\n",
        "        for i in range(20):\n",
        "            line = f.readline()\n",
        "            if not line:\n",
        "                break\n",
        "            print(line, end='')\n",
        "except FileNotFoundError:\n",
        "    print(f\"Error: File not found at {output_filename}\")\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred while reading the file: {e}\")"
      ],
      "id": "a7f124f6",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: File not found at hadamard_outputs_layer1.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "# from qiskit.quantum_info import Statevector # Although not strictly needed for the matrix multiplication, good for conceptual link\n",
        "# from qiskit import QuantumCircuit # Not needed for this calculation, but can be useful for visualization later if needed\n",
        "from google.colab import files # Import files for uploading\n",
        "import os # Import os for file existence check\n",
        "import struct # Import struct for binary conversion\n",
        "import math # Import math for using pi\n",
        "\n",
        "def float_to_ieee754_binary(f):\n",
        "    # Convert float to IEEE 754 double-precision binary (64-bit, big-endian)\n",
        "    packed = struct.pack('>d', f)\n",
        "    return ''.join(format(byte, '08b') for byte in packed)\n",
        "\n",
        "def to_amplitudes(val, max_val):\n",
        "    # Map to a in [-1, 1], then b = sqrt(1 - a^2) (clamped to avoid tiny negatives from rounding)\n",
        "    a = val / max_val\n",
        "    a = max(-1.0, min(1.0, a))\n",
        "    b = np.sqrt(max(0.0, 1.0 - a*a))\n",
        "    return np.array([a, b], dtype=float)\n",
        "\n",
        "def rx_gate(theta):\n",
        "    \"\"\"Returns the matrix for an RX rotation gate.\"\"\"\n",
        "    cos_theta_half = np.cos(theta / 2)\n",
        "    sin_theta_half = np.sin(theta / 2)\n",
        "    return np.array([[cos_theta_half, -1j * sin_theta_half],\n",
        "                     [-1j * sin_theta_half, cos_theta_half]], dtype=complex)\n",
        "\n",
        "\n",
        "# --- Step 1: Upload your file containing sigmoid values ---\n",
        "print(\"Please upload your file containing sigmoid values (one value per line):\")\n",
        "uploaded = files.upload()\n",
        "\n",
        "if not uploaded:\n",
        "    print(\"No file uploaded. Exiting.\")\n",
        "else:\n",
        "    infile = list(uploaded.keys())[0]\n",
        "    print(f\"Using file: {infile}\")\n",
        "\n",
        "    # --- Step 2: Read sigmoid values from the file ---\n",
        "    sigmoid_values = []\n",
        "    try:\n",
        "        with open(infile, \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
        "            for line in f:\n",
        "                s = line.strip()\n",
        "                # Check if the line contains \"sigmoid(out)=\" and extract the numeric value after it\n",
        "                if \"sigmoid(out)=\" in line:\n",
        "                    try:\n",
        "                        # Extract the value after \"sigmoid(out)=\"\n",
        "                        value_str = line.split(\"sigmoid(out)=\")[-1].strip()\n",
        "                        # Attempt to convert to float\n",
        "                        sigmoid_values.append(float(value_str))\n",
        "                    except ValueError:\n",
        "                        print(f\"Skipping line with non-float value after sigmoid(out)=: {line.strip()}\")\n",
        "                elif s: # Also handle lines that are just numbers\n",
        "                    try:\n",
        "                        sigmoid_values.append(float(s))\n",
        "                    except ValueError:\n",
        "                        print(f\"Skipping line with non-float value: {line.strip()}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error reading or parsing file {infile}: {e}\")\n",
        "        sigmoid_values = [] # Clear values if there was an error\n",
        "\n",
        "    if not sigmoid_values:\n",
        "        print(\"No valid integer sum values were extracted from the file. Please check the file content and the regex pattern.\")\n",
        "    else:\n",
        "        print(f\"Loaded {len(sigmoid_values)} sigmoid values.\")\n",
        "        print(\"First few:\", sigmoid_values[:5])\n",
        "\n",
        "        # --- Step 3: Define the rotation gate and normalization strategy ---\n",
        "        # Define the rotation angle (in radians)\n",
        "        rotation_angle = math.pi / 2 # Example: Pi/2 rotation around X-axis\n",
        "\n",
        "        # Get the matrix for the rotation gate\n",
        "        rotation_gate_matrix = rx_gate(rotation_angle)\n",
        "        print(f\"Using RX gate with angle: {rotation_angle:.4f} radians\")\n",
        "        print(\"Rotation gate matrix:\\n\", rotation_gate_matrix)\n",
        "\n",
        "\n",
        "        # For sigmoid values (0 to 1), the max value for normalization is typically 1.0\n",
        "        # If your sigmoid outputs are scaled differently, adjust max_value accordingly.\n",
        "        max_value = 1.0\n",
        "        print(\"Normalization max_value =\", max_value)\n",
        "\n",
        "        # --- Step 4: Apply the rotation gate to each value ---\n",
        "        results = []\n",
        "        for idx, sigmoid_val in enumerate(sigmoid_values):\n",
        "            state_in  = to_amplitudes(sigmoid_val, max_value)    # [a, b] where a is sigmoid_val\n",
        "            # Apply the rotation gate matrix\n",
        "            state_out = rotation_gate_matrix @ state_in                    # [out0, out1]\n",
        "\n",
        "            # Note: For real-valued inputs and RX gate, the output will have imaginary components.\n",
        "            # We'll take the absolute value squared for probabilities.\n",
        "            probs     = np.abs(state_out) ** 2          # [p0, p1]\n",
        "\n",
        "            results.append((idx, sigmoid_val, state_in[0], state_in[1],\n",
        "                            state_out[0], state_out[1], probs[0], probs[1]))\n",
        "\n",
        "        if results:\n",
        "            print(\"Example row:\\n(index, sigmoid_val, a, b, out0, out1, p0, p1)\\n\",\n",
        "                  results[0])\n",
        "        else:\n",
        "            print(\"No results generated.\")\n",
        "\n",
        "        # --- Step 5: Save detailed text log ---\n",
        "        # Use the requested output filename\n",
        "        output_txt_name = \"sigmoid_rotation.txt\" # Changed output filename\n",
        "        with open(output_txt_name, \"w\") as f:\n",
        "            for r in results:\n",
        "                f.write(f\"Index: {r[0]}, Sigmoid Value={r[1]:.6f}\\n\")\n",
        "                f.write(f\" Input state: [a={r[2]:.10f}, b={r[3]:.10f}]\\n\")\n",
        "                # Print complex output state values\n",
        "                f.write(f\" Output state: [out0={r[4]:.10f}, out1={r[5]:.10f}]\\n\")\n",
        "                f.write(f\" Probabilities: [p0={r[6]:.10f}, p1={r[7]:.10f}]\\n\")\n",
        "                f.write(\"-\" * 60 + \"\\n\")\n",
        "        print(\"Saved detailed output to:\", output_txt_name)\n",
        "\n",
        "        # --- Step 6: Save binary output file (optional, similar to previous work) ---\n",
        "        # Let's keep a binary output file as well, naming it consistently\n",
        "        # For binary output, decide which part of the complex number you need,\n",
        "        # or if you need a different representation. Here, we'll just save the real part\n",
        "        # of the element with the highest absolute value for simplicity, similar to before.\n",
        "        output_mem_name = os.path.splitext(infile)[0] + \"_rotation_full.mem\" # Changed output filename\n",
        "        with open(output_mem_name, \"w\") as f:\n",
        "            for r in results:\n",
        "                index, sigmoid_val, a, b, out0, out1, p0, p1 = r\n",
        "                # Consider the magnitude for determining 'highest'\n",
        "                highest_output_val = out0 if abs(out0) >= abs(out1) else out1\n",
        "                # Convert the real part of the highest output to binary\n",
        "                output_binary = float_to_ieee754_binary(highest_output_val.real)\n",
        "\n",
        "\n",
        "                # You might need a different binary format depending on your hardware\n",
        "                # For simplicity, let's just write the index and the binary output\n",
        "                f.write(f\"Index: {index}, Output (Binary 64bit - Real Part): {output_binary}\\n\") # Updated description\n",
        "        print(\"Saved binary output to:\", output_mem_name)\n",
        "\n",
        "\n",
        "        # Optional: Download the generated files\n",
        "        try:\n",
        "            files.download(output_txt_name)\n",
        "            files.download(output_mem_name)\n",
        "        except Exception as e:\n",
        "            print(f\"Could not automatically download files: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 275
        },
        "id": "yo93LlO_FO89",
        "outputId": "3374aa2f-220e-4781-8f33-e9af83c2fa36"
      },
      "id": "yo93LlO_FO89",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Please upload your file containing sigmoid values (one value per line):\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-330be644-9a03-4a4f-b71c-c6eb8845145e\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-330be644-9a03-4a4f-b71c-c6eb8845145e\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving L4-Sigmoid values.txt to L4-Sigmoid values (2).txt\n",
            "Using file: L4-Sigmoid values (2).txt\n",
            "Loaded 391 sigmoid values.\n",
            "First few: [16384.0, 16384.0, 16384.0, 16384.0, 16384.0]\n",
            "Normalization max_value = 1.0\n",
            "Example row:\n",
            "(index, sigmoid_val, a, b, out0, out1, p0, p1)\n",
            " (0, 16384.0, np.float64(1.0), np.float64(0.0), np.float64(0.7071067811865475), np.float64(0.7071067811865475), np.float64(0.4999999999999999), np.float64(0.4999999999999999))\n",
            "Saved detailed output to: sigmoid_HT.txt\n",
            "Saved binary output to: L4-Sigmoid values (2)_hadamard_full.mem\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_f6f1a620-59f7-4733-9f61-c0a19e3d938b\", \"sigmoid_HT.txt\", 97980)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_cb999335-ca28-44b5-b86a-6aa0f480777a\", \"L4-Sigmoid values (2)_hadamard_full.mem\", 38990)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from google.colab import files\n",
        "import os\n",
        "import struct\n",
        "import re # Import regex for parsing lines\n",
        "\n",
        "def float_to_ieee754_binary(f):\n",
        "    # Convert float to IEEE 754 double-precision binary (64-bit, big-endian)\n",
        "    packed = struct.pack('>d', f)\n",
        "    return ''.join(format(byte, '08b') for byte in packed)\n",
        "\n",
        "def to_amplitudes(val, max_val):\n",
        "    # Normalize value to be within [-1, 1], then calculate the corresponding 'b' for a 2-element state vector\n",
        "    a = val / max_val\n",
        "    # Clamp 'a' to the valid range to avoid issues with sqrt of negative numbers due to floating point inaccuracies\n",
        "    a = max(-1.0, min(1.0, a))\n",
        "    b = np.sqrt(max(0.0, 1.0 - a*a))\n",
        "    return np.array([a, b], dtype=float)\n",
        "\n",
        "# --- Step 1: Upload your file containing frame values ---\n",
        "print(\"Please upload your file containing frame values (one value per line):\")\n",
        "uploaded = files.upload()\n",
        "\n",
        "if not uploaded:\n",
        "    print(\"No file uploaded. Exiting.\")\n",
        "else:\n",
        "    infile = list(uploaded.keys())[0]\n",
        "    print(f\"Using file: {infile}\")\n",
        "\n",
        "    # --- Step 2: Read frame values from the file ---\n",
        "    frame_values = []\n",
        "    # Regex to capture the integer after \"frame=\" or just the integer on a line\n",
        "    # This pattern is more flexible to handle lines like \"frame=12345\" or just \"12345\"\n",
        "    pat = re.compile(r'(?:frame\\s*=\\s*)?(\\d+)')\n",
        "    try:\n",
        "        with open(infile, \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
        "            for line in f:\n",
        "                s = line.strip()\n",
        "                if s:\n",
        "                    m = pat.search(line)\n",
        "                    if m:\n",
        "                        try:\n",
        "                            # Convert captured string to integer\n",
        "                            frame_values.append(int(m.group(1)))\n",
        "                        except ValueError:\n",
        "                            print(f\"Skipping line with non-integer frame value: {line.strip()}\")\n",
        "                    # else:\n",
        "                         # print(f\"Skipping line with no frame value found: {line.strip()}\") # Optional: uncomment to see skipped lines\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error reading or parsing file {infile}: {e}\")\n",
        "        frame_values = [] # Clear values if there was an error\n",
        "\n",
        "\n",
        "    if not frame_values:\n",
        "        print(\"No valid integer frame values were extracted from the file. Please check the file content and the regex pattern.\")\n",
        "    else:\n",
        "        print(f\"Loaded {len(frame_values)} frame values.\")\n",
        "        print(\"First few:\", frame_values[:5])\n",
        "\n",
        "        # --- Step 3: Define the Hadamard gate and normalization strategy ---\n",
        "        Hadamard_gate_matrix = np.array([[1, 1],\n",
        "                                          [1, -1]], dtype=float) / np.sqrt(2.0)\n",
        "\n",
        "        print(\"Using Hadamard gate matrix:\\n\", Hadamard_gate_matrix)\n",
        "\n",
        "        # Determine the maximum value for normalization. Using the max value in the data is common.\n",
        "        # If you have a known hardware maximum or expected range, you might use that instead.\n",
        "        USE_FIXED_SCALE = False            # set True to use a fixed number like your hardware max\n",
        "        FIXED_MAX_VALUE = 4286639746.0     # <- put your known scale here if using fixed\n",
        "\n",
        "        if USE_FIXED_SCALE:\n",
        "            max_value = float(FIXED_MAX_VALUE)\n",
        "        else:\n",
        "            # data-driven scale: use the maximum absolute value seen\n",
        "            max_value = float(max(1, max(abs(v) for v in frame_values))) # Use abs() in case of negative values\n",
        "\n",
        "        print(\"Normalization max_value =\", max_value)\n",
        "\n",
        "        # --- Step 4: Apply the Hadamard transform to each frame value and print ---\n",
        "        results = []\n",
        "        print(\"\\nHadamard Transform Equivalents:\")\n",
        "        print(\"---------------------------------\")\n",
        "        for idx, frame_val in enumerate(frame_values):\n",
        "            state_in  = to_amplitudes(frame_val, max_value)    # [a, b] where a is normalized frame_val\n",
        "            # Apply the Hadamard gate matrix\n",
        "            state_out = Hadamard_gate_matrix @ state_in        # [out0, out1]\n",
        "\n",
        "            # Probabilities are the absolute value squared of the output state elements\n",
        "            probs     = np.abs(state_out) ** 2          # [p0, p1]\n",
        "\n",
        "            results.append((idx, frame_val, state_in[0], state_in[1],\n",
        "                            state_out[0], state_out[1], probs[0], probs[1]))\n",
        "\n",
        "            # Print in the requested format\n",
        "            print(f\"i_data[{idx}] = {frame_val} (0x{frame_val:X}) ---> Hadamard equivalent: [{state_out[0]:.6f}, {state_out[1]:.6f}] (Probabilities: [{probs[0]:.6f}, {probs[1]:.6f}])\")\n",
        "\n",
        "        if results:\n",
        "            print(\"\\nExample row:\\n(index, frame_val, a, b, out0, out1, p0, p1)\\n\",\n",
        "                  results[0])\n",
        "        else:\n",
        "            print(\"\\nNo results generated.\")\n",
        "\n",
        "        # --- Step 5: Save output as a Verilog lookup table (.mem) file ---\n",
        "        # Determine the output filename based on the input filename\n",
        "        base_filename = os.path.splitext(infile)[0]\n",
        "        output_mem_name = f\"{base_filename}_hadamard_lookup.mem\"\n",
        "\n",
        "        # Verilog memory file format: @address data\n",
        "        # We will store the binary representation of the highest absolute value of the output state elements.\n",
        "        # You might need to adjust the format based on your specific Verilog module requirements\n",
        "        # (e.g., fixed-point representation, smaller bit width).\n",
        "        # For this example, we'll use the 64-bit IEEE 754 binary representation of the highest output (real part).\n",
        "\n",
        "        with open(output_mem_name, \"w\") as f:\n",
        "            f.write(\"// Verilog Lookup Table for Hadamard Transform Equivalents\\n\")\n",
        "            f.write(f\"// Generated from file: {infile}\\n\")\n",
        "            f.write(f\"// Normalization max value: {max_value}\\n\")\n",
        "            f.write(f\"// Number of entries: {len(results)}\\n\")\n",
        "            f.write(\"// Format: @address Highest_Output_Binary (64-bit IEEE 754 real part)\\n\")\n",
        "\n",
        "            for r in results:\n",
        "                index, frame_val, a, b, out0, out1, p0, p1 = r\n",
        "\n",
        "                # Choose the output element with the highest absolute value\n",
        "                highest_output_val = out0 if abs(out0) >= abs(out1) else out1\n",
        "\n",
        "                # Convert the real part of the highest output to binary (64-bit IEEE 754)\n",
        "                output_binary = float_to_ieee754_binary(highest_output_val.real)\n",
        "\n",
        "                # Format as Verilog memory entry\n",
        "                # Address will be the index in hexadecimal\n",
        "                f.write(f\"@{index:04x} {output_binary}\\n\") # Using 4 hex digits for address, adjust as needed\n",
        "\n",
        "        print(\"\\nSaved Verilog lookup table to:\", output_mem_name)\n",
        "\n",
        "        # Optional: Download the generated file\n",
        "        try:\n",
        "            files.download(output_mem_name)\n",
        "        except Exception as e:\n",
        "            print(f\"Could not automatically download file: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "4oMgfYhkUxHq",
        "outputId": "aa218c91-92f6-44af-eef9-705004679ec3"
      },
      "id": "4oMgfYhkUxHq",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Please upload your file containing frame values (one value per line):\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-658fc07f-912c-4195-ac1a-b79be45496f9\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-658fc07f-912c-4195-ac1a-b79be45496f9\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving max_finder frame.txt to max_finder frame (1).txt\n",
            "Using file: max_finder frame (1).txt\n",
            "Loaded 1125 frame values.\n",
            "First few: [9085000, 0, 1, 2, 3]\n",
            "Using Hadamard gate matrix:\n",
            " [[ 0.70710678  0.70710678]\n",
            " [ 0.70710678 -0.70710678]]\n",
            "Normalization max_value = 900085000.0\n",
            "\n",
            "Hadamard Transform Equivalents:\n",
            "---------------------------------\n",
            "i_data[0] = 9085000 (0x8AA048) ---> Hadamard equivalent: [0.714208, -0.699934] (Probabilities: [0.510093, 0.489907])\n",
            "i_data[1] = 0 (0x0) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[2] = 1 (0x1) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[3] = 2 (0x2) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[4] = 3 (0x3) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[5] = 4 (0x4) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[6] = 5 (0x5) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[7] = 6 (0x6) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[8] = 7 (0x7) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[9] = 8 (0x8) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[10] = 9 (0x9) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[11] = 18085000 (0x113F488) ---> Hadamard equivalent: [0.721172, -0.692756] (Probabilities: [0.520088, 0.479912])\n",
            "i_data[12] = 0 (0x0) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[13] = 1 (0x1) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[14] = 2 (0x2) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[15] = 3 (0x3) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[16] = 4 (0x4) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[17] = 5 (0x5) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[18] = 6 (0x6) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[19] = 7 (0x7) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[20] = 8 (0x8) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[21] = 9 (0x9) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[22] = 27085000 (0x19D48C8) ---> Hadamard equivalent: [0.728065, -0.685509] (Probabilities: [0.530078, 0.469922])\n",
            "i_data[23] = 0 (0x0) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[24] = 1 (0x1) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[25] = 2 (0x2) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[26] = 3 (0x3) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[27] = 4 (0x4) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[28] = 5 (0x5) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[29] = 6 (0x6) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[30] = 7 (0x7) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[31] = 8 (0x8) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[32] = 9 (0x9) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[33] = 36085000 (0x2269D08) ---> Hadamard equivalent: [0.734887, -0.678190] (Probabilities: [0.540058, 0.459942])\n",
            "i_data[34] = 0 (0x0) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[35] = 1 (0x1) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[36] = 2 (0x2) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[37] = 3 (0x3) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[38] = 4 (0x4) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[39] = 5 (0x5) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[40] = 6 (0x6) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[41] = 7 (0x7) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[42] = 8 (0x8) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[43] = 9 (0x9) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[44] = 45085000 (0x2AFF148) ---> Hadamard equivalent: [0.741638, -0.670800] (Probabilities: [0.550027, 0.449973])\n",
            "i_data[45] = 0 (0x0) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[46] = 1 (0x1) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[47] = 2 (0x2) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[48] = 3 (0x3) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[49] = 4 (0x4) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[50] = 5 (0x5) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[51] = 6 (0x6) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[52] = 7 (0x7) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[53] = 8 (0x8) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[54] = 9 (0x9) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[55] = 54085000 (0x3394588) ---> Hadamard equivalent: [0.748318, -0.663340] (Probabilities: [0.559980, 0.440020])\n",
            "i_data[56] = 0 (0x0) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[57] = 1 (0x1) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[58] = 2 (0x2) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[59] = 3 (0x3) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[60] = 4 (0x4) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[61] = 5 (0x5) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[62] = 6 (0x6) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[63] = 7 (0x7) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[64] = 8 (0x8) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[65] = 9 (0x9) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[66] = 63085000 (0x3C299C8) ---> Hadamard equivalent: [0.754927, -0.655808] (Probabilities: [0.569915, 0.430085])\n",
            "i_data[67] = 0 (0x0) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[68] = 1 (0x1) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[69] = 2 (0x2) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[70] = 3 (0x3) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[71] = 4 (0x4) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[72] = 5 (0x5) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[73] = 6 (0x6) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[74] = 7 (0x7) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[75] = 8 (0x8) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[76] = 9 (0x9) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[77] = 72085000 (0x44BEE08) ---> Hadamard equivalent: [0.761465, -0.648205] (Probabilities: [0.579830, 0.420170])\n",
            "i_data[78] = 0 (0x0) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[79] = 1 (0x1) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[80] = 2 (0x2) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[81] = 3 (0x3) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[82] = 4 (0x4) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[83] = 5 (0x5) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[84] = 6 (0x6) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[85] = 7 (0x7) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[86] = 8 (0x8) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[87] = 9 (0x9) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[88] = 81085000 (0x4D54248) ---> Hadamard equivalent: [0.767932, -0.640531] (Probabilities: [0.589720, 0.410280])\n",
            "i_data[89] = 0 (0x0) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[90] = 1 (0x1) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[91] = 2 (0x2) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[92] = 3 (0x3) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[93] = 4 (0x4) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[94] = 5 (0x5) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[95] = 6 (0x6) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[96] = 7 (0x7) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[97] = 8 (0x8) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[98] = 9 (0x9) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[99] = 90085000 (0x55E9688) ---> Hadamard equivalent: [0.774327, -0.632786] (Probabilities: [0.599582, 0.400418])\n",
            "i_data[100] = 0 (0x0) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[101] = 1 (0x1) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[102] = 2 (0x2) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[103] = 3 (0x3) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[104] = 4 (0x4) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[105] = 5 (0x5) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[106] = 6 (0x6) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[107] = 7 (0x7) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[108] = 8 (0x8) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[109] = 9 (0x9) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[110] = 99085000 (0x5E7EAC8) ---> Hadamard equivalent: [0.780650, -0.624968] (Probabilities: [0.609415, 0.390585])\n",
            "i_data[111] = 0 (0x0) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[112] = 1 (0x1) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[113] = 2 (0x2) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[114] = 3 (0x3) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[115] = 4 (0x4) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[116] = 5 (0x5) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[117] = 6 (0x6) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[118] = 7 (0x7) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[119] = 8 (0x8) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[120] = 9 (0x9) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[121] = 108085000 (0x6713F08) ---> Hadamard equivalent: [0.786902, -0.617078] (Probabilities: [0.619214, 0.380786])\n",
            "i_data[122] = 0 (0x0) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[123] = 1 (0x1) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[124] = 2 (0x2) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[125] = 3 (0x3) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[126] = 4 (0x4) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[127] = 5 (0x5) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[128] = 6 (0x6) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[129] = 7 (0x7) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[130] = 8 (0x8) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[131] = 9 (0x9) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[132] = 117085000 (0x6FA9348) ---> Hadamard equivalent: [0.793081, -0.609117] (Probabilities: [0.628977, 0.371023])\n",
            "i_data[133] = 0 (0x0) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[134] = 1 (0x1) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[135] = 2 (0x2) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[136] = 3 (0x3) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[137] = 4 (0x4) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[138] = 5 (0x5) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[139] = 6 (0x6) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[140] = 7 (0x7) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[141] = 8 (0x8) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[142] = 9 (0x9) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[143] = 126085000 (0x783E788) ---> Hadamard equivalent: [0.799187, -0.601082] (Probabilities: [0.638700, 0.361300])\n",
            "i_data[144] = 0 (0x0) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[145] = 1 (0x1) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[146] = 2 (0x2) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[147] = 3 (0x3) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[148] = 4 (0x4) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[149] = 5 (0x5) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[150] = 6 (0x6) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[151] = 7 (0x7) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[152] = 8 (0x8) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[153] = 9 (0x9) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[154] = 135085000 (0x80D3BC8) ---> Hadamard equivalent: [0.805221, -0.592975] (Probabilities: [0.648380, 0.351620])\n",
            "i_data[155] = 0 (0x0) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[156] = 1 (0x1) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[157] = 2 (0x2) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[158] = 3 (0x3) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[159] = 4 (0x4) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[160] = 5 (0x5) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[161] = 6 (0x6) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[162] = 7 (0x7) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[163] = 8 (0x8) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[164] = 9 (0x9) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[165] = 144085000 (0x8969008) ---> Hadamard equivalent: [0.811181, -0.584795] (Probabilities: [0.658015, 0.341985])\n",
            "i_data[166] = 0 (0x0) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[167] = 1 (0x1) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[168] = 2 (0x2) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[169] = 3 (0x3) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[170] = 4 (0x4) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[171] = 5 (0x5) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[172] = 6 (0x6) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[173] = 7 (0x7) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[174] = 8 (0x8) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[175] = 9 (0x9) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[176] = 153085000 (0x91FE448) ---> Hadamard equivalent: [0.817068, -0.576541] (Probabilities: [0.667600, 0.332400])\n",
            "i_data[177] = 0 (0x0) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[178] = 1 (0x1) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[179] = 2 (0x2) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[180] = 3 (0x3) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[181] = 4 (0x4) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[182] = 5 (0x5) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[183] = 6 (0x6) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[184] = 7 (0x7) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[185] = 8 (0x8) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[186] = 9 (0x9) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[187] = 162085000 (0x9A93888) ---> Hadamard equivalent: [0.822881, -0.568213] (Probabilities: [0.677134, 0.322866])\n",
            "i_data[188] = 0 (0x0) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[189] = 1 (0x1) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[190] = 2 (0x2) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[191] = 3 (0x3) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[192] = 4 (0x4) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[193] = 5 (0x5) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[194] = 6 (0x6) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[195] = 7 (0x7) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[196] = 8 (0x8) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[197] = 9 (0x9) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[198] = 171085000 (0xA328CC8) ---> Hadamard equivalent: [0.828620, -0.559811] (Probabilities: [0.686611, 0.313389])\n",
            "i_data[199] = 0 (0x0) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[200] = 1 (0x1) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[201] = 2 (0x2) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[202] = 3 (0x3) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[203] = 4 (0x4) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[204] = 5 (0x5) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[205] = 6 (0x6) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[206] = 7 (0x7) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[207] = 8 (0x8) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[208] = 9 (0x9) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[209] = 180085000 (0xABBE108) ---> Hadamard equivalent: [0.834284, -0.551335] (Probabilities: [0.696030, 0.303970])\n",
            "i_data[210] = 0 (0x0) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[211] = 1 (0x1) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[212] = 2 (0x2) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[213] = 3 (0x3) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[214] = 4 (0x4) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[215] = 5 (0x5) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[216] = 6 (0x6) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[217] = 7 (0x7) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[218] = 8 (0x8) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[219] = 9 (0x9) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[220] = 189085000 (0xB453548) ---> Hadamard equivalent: [0.839873, -0.542783] (Probabilities: [0.705387, 0.294613])\n",
            "i_data[221] = 0 (0x0) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[222] = 1 (0x1) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[223] = 2 (0x2) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[224] = 3 (0x3) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[225] = 4 (0x4) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[226] = 5 (0x5) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[227] = 6 (0x6) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[228] = 7 (0x7) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[229] = 8 (0x8) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[230] = 9 (0x9) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[231] = 198085000 (0xBCE8988) ---> Hadamard equivalent: [0.845386, -0.534155] (Probabilities: [0.714678, 0.285322])\n",
            "i_data[232] = 0 (0x0) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[233] = 1 (0x1) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[234] = 2 (0x2) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[235] = 3 (0x3) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[236] = 4 (0x4) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[237] = 5 (0x5) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[238] = 6 (0x6) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[239] = 7 (0x7) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[240] = 8 (0x8) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[241] = 9 (0x9) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[242] = 207085000 (0xC57DDC8) ---> Hadamard equivalent: [0.850824, -0.525452] (Probabilities: [0.723901, 0.276099])\n",
            "i_data[243] = 0 (0x0) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[244] = 1 (0x1) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[245] = 2 (0x2) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[246] = 3 (0x3) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[247] = 4 (0x4) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[248] = 5 (0x5) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[249] = 6 (0x6) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[250] = 7 (0x7) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[251] = 8 (0x8) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[252] = 9 (0x9) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[253] = 216075000 (0xCE10AF8) ---> Hadamard equivalent: [0.856178, -0.516681] (Probabilities: [0.733041, 0.266959])\n",
            "i_data[254] = 216085000 (0xCE13208) ---> Hadamard equivalent: [0.856184, -0.516671] (Probabilities: [0.733051, 0.266949])\n",
            "i_data[255] = 0 (0x0) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[256] = 1 (0x1) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[257] = 2 (0x2) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[258] = 3 (0x3) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[259] = 4 (0x4) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[260] = 5 (0x5) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[261] = 6 (0x6) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[262] = 7 (0x7) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[263] = 8 (0x8) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[264] = 9 (0x9) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[265] = 225075000 (0xD6A5F38) ---> Hadamard equivalent: [0.861461, -0.507823] (Probabilities: [0.742115, 0.257885])\n",
            "i_data[266] = 225085000 (0xD6A8648) ---> Hadamard equivalent: [0.861467, -0.507813] (Probabilities: [0.742125, 0.257875])\n",
            "i_data[267] = 0 (0x0) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[268] = 1 (0x1) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[269] = 2 (0x2) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[270] = 3 (0x3) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[271] = 4 (0x4) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[272] = 5 (0x5) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[273] = 6 (0x6) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[274] = 7 (0x7) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[275] = 8 (0x8) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[276] = 9 (0x9) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[277] = 234085000 (0xDF3DA88) ---> Hadamard equivalent: [0.866672, -0.498878] (Probabilities: [0.751121, 0.248879])\n",
            "i_data[278] = 0 (0x0) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[279] = 1 (0x1) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[280] = 2 (0x2) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[281] = 3 (0x3) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[282] = 4 (0x4) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[283] = 5 (0x5) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[284] = 6 (0x6) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[285] = 7 (0x7) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[286] = 8 (0x8) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[287] = 9 (0x9) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[288] = 243085000 (0xE7D2EC8) ---> Hadamard equivalent: [0.871799, -0.489864] (Probabilities: [0.760033, 0.239967])\n",
            "i_data[289] = 0 (0x0) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[290] = 1 (0x1) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[291] = 2 (0x2) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[292] = 3 (0x3) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[293] = 4 (0x4) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[294] = 5 (0x5) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[295] = 6 (0x6) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[296] = 7 (0x7) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[297] = 8 (0x8) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[298] = 9 (0x9) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[299] = 252085000 (0xF068308) ---> Hadamard equivalent: [0.876846, -0.480771] (Probabilities: [0.768860, 0.231140])\n",
            "i_data[300] = 0 (0x0) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[301] = 1 (0x1) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[302] = 2 (0x2) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[303] = 3 (0x3) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[304] = 4 (0x4) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[305] = 5 (0x5) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[306] = 6 (0x6) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[307] = 7 (0x7) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[308] = 8 (0x8) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[309] = 9 (0x9) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[310] = 261085000 (0xF8FD748) ---> Hadamard equivalent: [0.881814, -0.471597] (Probabilities: [0.777596, 0.222404])\n",
            "i_data[311] = 0 (0x0) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[312] = 1 (0x1) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[313] = 2 (0x2) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[314] = 3 (0x3) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[315] = 4 (0x4) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[316] = 5 (0x5) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[317] = 6 (0x6) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[318] = 7 (0x7) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[319] = 8 (0x8) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[320] = 9 (0x9) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[321] = 270085000 (0x10192B88) ---> Hadamard equivalent: [0.886701, -0.462343] (Probabilities: [0.786239, 0.213761])\n",
            "i_data[322] = 0 (0x0) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[323] = 1 (0x1) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[324] = 2 (0x2) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[325] = 3 (0x3) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[326] = 4 (0x4) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[327] = 5 (0x5) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[328] = 6 (0x6) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[329] = 7 (0x7) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[330] = 8 (0x8) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[331] = 9 (0x9) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[332] = 279085000 (0x10A27FC8) ---> Hadamard equivalent: [0.891506, -0.453008] (Probabilities: [0.794784, 0.205216])\n",
            "i_data[333] = 0 (0x0) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[334] = 1 (0x1) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[335] = 2 (0x2) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[336] = 3 (0x3) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[337] = 4 (0x4) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[338] = 5 (0x5) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[339] = 6 (0x6) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[340] = 7 (0x7) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[341] = 8 (0x8) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[342] = 9 (0x9) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[343] = 288085000 (0x112BD408) ---> Hadamard equivalent: [0.896230, -0.443590] (Probabilities: [0.803228, 0.196772])\n",
            "i_data[344] = 0 (0x0) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[345] = 1 (0x1) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[346] = 2 (0x2) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[347] = 3 (0x3) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[348] = 4 (0x4) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[349] = 5 (0x5) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[350] = 6 (0x6) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[351] = 7 (0x7) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[352] = 8 (0x8) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[353] = 9 (0x9) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[354] = 297085000 (0x11B52848) ---> Hadamard equivalent: [0.900870, -0.434090] (Probabilities: [0.811566, 0.188434])\n",
            "i_data[355] = 0 (0x0) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[356] = 1 (0x1) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[357] = 2 (0x2) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[358] = 3 (0x3) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[359] = 4 (0x4) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[360] = 5 (0x5) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[361] = 6 (0x6) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[362] = 7 (0x7) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[363] = 8 (0x8) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[364] = 9 (0x9) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[365] = 306085000 (0x123E7C88) ---> Hadamard equivalent: [0.905426, -0.424505] (Probabilities: [0.819796, 0.180204])\n",
            "i_data[366] = 0 (0x0) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[367] = 1 (0x1) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[368] = 2 (0x2) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[369] = 3 (0x3) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[370] = 4 (0x4) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[371] = 5 (0x5) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[372] = 6 (0x6) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[373] = 7 (0x7) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[374] = 8 (0x8) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[375] = 9 (0x9) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[376] = 315085000 (0x12C7D0C8) ---> Hadamard equivalent: [0.909897, -0.414835] (Probabilities: [0.827912, 0.172088])\n",
            "i_data[377] = 0 (0x0) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[378] = 1 (0x1) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[379] = 2 (0x2) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[380] = 3 (0x3) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[381] = 4 (0x4) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[382] = 5 (0x5) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[383] = 6 (0x6) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[384] = 7 (0x7) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[385] = 8 (0x8) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[386] = 9 (0x9) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[387] = 324085000 (0x13512508) ---> Hadamard equivalent: [0.914282, -0.405079] (Probabilities: [0.835911, 0.164089])\n",
            "i_data[388] = 0 (0x0) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[389] = 1 (0x1) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[390] = 2 (0x2) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[391] = 3 (0x3) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[392] = 4 (0x4) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[393] = 5 (0x5) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[394] = 6 (0x6) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[395] = 7 (0x7) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[396] = 8 (0x8) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[397] = 9 (0x9) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[398] = 333085000 (0x13DA7948) ---> Hadamard equivalent: [0.918579, -0.395236] (Probabilities: [0.843788, 0.156212])\n",
            "i_data[399] = 0 (0x0) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[400] = 1 (0x1) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[401] = 2 (0x2) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[402] = 3 (0x3) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[403] = 4 (0x4) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[404] = 5 (0x5) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[405] = 6 (0x6) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[406] = 7 (0x7) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[407] = 8 (0x8) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[408] = 9 (0x9) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[409] = 342085000 (0x1463CD88) ---> Hadamard equivalent: [0.922789, -0.385305] (Probabilities: [0.851540, 0.148460])\n",
            "i_data[410] = 0 (0x0) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[411] = 1 (0x1) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[412] = 2 (0x2) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[413] = 3 (0x3) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[414] = 4 (0x4) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[415] = 5 (0x5) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[416] = 6 (0x6) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[417] = 7 (0x7) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[418] = 8 (0x8) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[419] = 9 (0x9) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[420] = 351085000 (0x14ED21C8) ---> Hadamard equivalent: [0.926910, -0.375285] (Probabilities: [0.859161, 0.140839])\n",
            "i_data[421] = 0 (0x0) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[422] = 1 (0x1) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[423] = 2 (0x2) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[424] = 3 (0x3) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[425] = 4 (0x4) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[426] = 5 (0x5) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[427] = 6 (0x6) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[428] = 7 (0x7) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[429] = 8 (0x8) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[430] = 9 (0x9) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[431] = 360085000 (0x15767608) ---> Hadamard equivalent: [0.930939, -0.365174] (Probabilities: [0.866648, 0.133352])\n",
            "i_data[432] = 0 (0x0) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[433] = 1 (0x1) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[434] = 2 (0x2) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[435] = 3 (0x3) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[436] = 4 (0x4) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[437] = 5 (0x5) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[438] = 6 (0x6) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[439] = 7 (0x7) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[440] = 8 (0x8) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[441] = 9 (0x9) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[442] = 369085000 (0x15FFCA48) ---> Hadamard equivalent: [0.934877, -0.354971] (Probabilities: [0.873996, 0.126004])\n",
            "i_data[443] = 0 (0x0) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[444] = 1 (0x1) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[445] = 2 (0x2) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[446] = 3 (0x3) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[447] = 4 (0x4) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[448] = 5 (0x5) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[449] = 6 (0x6) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[450] = 7 (0x7) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[451] = 8 (0x8) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[452] = 9 (0x9) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[453] = 378085000 (0x16891E88) ---> Hadamard equivalent: [0.938722, -0.344675] (Probabilities: [0.881199, 0.118801])\n",
            "i_data[454] = 0 (0x0) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[455] = 1 (0x1) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[456] = 2 (0x2) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[457] = 3 (0x3) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[458] = 4 (0x4) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[459] = 5 (0x5) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[460] = 6 (0x6) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[461] = 7 (0x7) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[462] = 8 (0x8) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[463] = 9 (0x9) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[464] = 387085000 (0x171272C8) ---> Hadamard equivalent: [0.942472, -0.334284] (Probabilities: [0.888254, 0.111746])\n",
            "i_data[465] = 0 (0x0) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[466] = 1 (0x1) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[467] = 2 (0x2) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[468] = 3 (0x3) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[469] = 4 (0x4) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[470] = 5 (0x5) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[471] = 6 (0x6) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[472] = 7 (0x7) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[473] = 8 (0x8) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[474] = 9 (0x9) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[475] = 396085000 (0x179BC708) ---> Hadamard equivalent: [0.946126, -0.323798] (Probabilities: [0.895155, 0.104845])\n",
            "i_data[476] = 0 (0x0) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[477] = 1 (0x1) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[478] = 2 (0x2) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[479] = 3 (0x3) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[480] = 4 (0x4) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[481] = 5 (0x5) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[482] = 6 (0x6) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[483] = 7 (0x7) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[484] = 8 (0x8) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[485] = 9 (0x9) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[486] = 396085000 (0x179BC708) ---> Hadamard equivalent: [0.946126, -0.323798] (Probabilities: [0.895155, 0.104845])\n",
            "i_data[487] = 396095000 (0x179BEE18) ---> Hadamard equivalent: [0.946130, -0.323786] (Probabilities: [0.895163, 0.104837])\n",
            "i_data[488] = 396105000 (0x179C1528) ---> Hadamard equivalent: [0.946134, -0.323774] (Probabilities: [0.895170, 0.104830])\n",
            "i_data[489] = 396115000 (0x179C3C38) ---> Hadamard equivalent: [0.946138, -0.323762] (Probabilities: [0.895178, 0.104822])\n",
            "i_data[490] = 396125000 (0x179C6348) ---> Hadamard equivalent: [0.946142, -0.323751] (Probabilities: [0.895185, 0.104815])\n",
            "i_data[491] = 396135000 (0x179C8A58) ---> Hadamard equivalent: [0.946146, -0.323739] (Probabilities: [0.895193, 0.104807])\n",
            "i_data[492] = 396145000 (0x179CB168) ---> Hadamard equivalent: [0.946150, -0.323727] (Probabilities: [0.895201, 0.104799])\n",
            "i_data[493] = 396155000 (0x179CD878) ---> Hadamard equivalent: [0.946154, -0.323716] (Probabilities: [0.895208, 0.104792])\n",
            "i_data[494] = 396165000 (0x179CFF88) ---> Hadamard equivalent: [0.946158, -0.323704] (Probabilities: [0.895216, 0.104784])\n",
            "i_data[495] = 396175000 (0x179D2698) ---> Hadamard equivalent: [0.946162, -0.323692] (Probabilities: [0.895223, 0.104777])\n",
            "i_data[496] = 396185000 (0x179D4DA8) ---> Hadamard equivalent: [0.946166, -0.323681] (Probabilities: [0.895231, 0.104769])\n",
            "i_data[497] = 44 (0x2C) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[498] = 404965000 (0x18234688) ---> Hadamard equivalent: [0.949636, -0.313355] (Probabilities: [0.901809, 0.098191])\n",
            "i_data[499] = 404975000 (0x18236D98) ---> Hadamard equivalent: [0.949640, -0.313343] (Probabilities: [0.901816, 0.098184])\n",
            "i_data[500] = 404985000 (0x182394A8) ---> Hadamard equivalent: [0.949644, -0.313331] (Probabilities: [0.901823, 0.098177])\n",
            "i_data[501] = 404995000 (0x1823BBB8) ---> Hadamard equivalent: [0.949648, -0.313320] (Probabilities: [0.901831, 0.098169])\n",
            "i_data[502] = 405005000 (0x1823E2C8) ---> Hadamard equivalent: [0.949652, -0.313308] (Probabilities: [0.901838, 0.098162])\n",
            "i_data[503] = 405015000 (0x182409D8) ---> Hadamard equivalent: [0.949656, -0.313296] (Probabilities: [0.901846, 0.098154])\n",
            "i_data[504] = 405025000 (0x182430E8) ---> Hadamard equivalent: [0.949659, -0.313284] (Probabilities: [0.901853, 0.098147])\n",
            "i_data[505] = 405035000 (0x182457F8) ---> Hadamard equivalent: [0.949663, -0.313272] (Probabilities: [0.901860, 0.098140])\n",
            "i_data[506] = 405045000 (0x18247F08) ---> Hadamard equivalent: [0.949667, -0.313261] (Probabilities: [0.901868, 0.098132])\n",
            "i_data[507] = 405055000 (0x1824A618) ---> Hadamard equivalent: [0.949671, -0.313249] (Probabilities: [0.901875, 0.098125])\n",
            "i_data[508] = 405075000 (0x1824F438) ---> Hadamard equivalent: [0.949679, -0.313225] (Probabilities: [0.901890, 0.098110])\n",
            "i_data[509] = 405085000 (0x18251B48) ---> Hadamard equivalent: [0.949683, -0.313213] (Probabilities: [0.901897, 0.098103])\n",
            "i_data[510] = 0 (0x0) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[511] = 1 (0x1) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[512] = 2 (0x2) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[513] = 3 (0x3) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[514] = 4 (0x4) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[515] = 5 (0x5) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[516] = 6 (0x6) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[517] = 7 (0x7) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[518] = 8 (0x8) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[519] = 9 (0x9) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[520] = 414085000 (0x18AE6F88) ---> Hadamard equivalent: [0.953140, -0.302530] (Probabilities: [0.908476, 0.091524])\n",
            "i_data[521] = 0 (0x0) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[522] = 1 (0x1) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[523] = 2 (0x2) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[524] = 3 (0x3) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[525] = 4 (0x4) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[526] = 5 (0x5) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[527] = 6 (0x6) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[528] = 7 (0x7) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[529] = 8 (0x8) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[530] = 9 (0x9) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[531] = 423085000 (0x1937C3C8) ---> Hadamard equivalent: [0.956496, -0.291745] (Probabilities: [0.914885, 0.085115])\n",
            "i_data[532] = 0 (0x0) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[533] = 1 (0x1) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[534] = 2 (0x2) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[535] = 3 (0x3) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[536] = 4 (0x4) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[537] = 5 (0x5) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[538] = 6 (0x6) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[539] = 7 (0x7) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[540] = 8 (0x8) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[541] = 9 (0x9) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[542] = 432085000 (0x19C11808) ---> Hadamard equivalent: [0.959749, -0.280858] (Probabilities: [0.921119, 0.078881])\n",
            "i_data[543] = 0 (0x0) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[544] = 1 (0x1) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[545] = 2 (0x2) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[546] = 3 (0x3) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[547] = 4 (0x4) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[548] = 5 (0x5) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[549] = 6 (0x6) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[550] = 7 (0x7) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[551] = 8 (0x8) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[552] = 9 (0x9) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[553] = 441085000 (0x1A4A6C48) ---> Hadamard equivalent: [0.962898, -0.269865] (Probabilities: [0.927173, 0.072827])\n",
            "i_data[554] = 0 (0x0) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[555] = 1 (0x1) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[556] = 2 (0x2) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[557] = 3 (0x3) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[558] = 4 (0x4) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[559] = 5 (0x5) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[560] = 6 (0x6) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[561] = 7 (0x7) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[562] = 8 (0x8) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[563] = 9 (0x9) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[564] = 450085000 (0x1AD3C088) ---> Hadamard equivalent: [0.965940, -0.258766] (Probabilities: [0.933040, 0.066960])\n",
            "i_data[565] = 0 (0x0) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[566] = 1 (0x1) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[567] = 2 (0x2) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[568] = 3 (0x3) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[569] = 4 (0x4) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[570] = 5 (0x5) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[571] = 6 (0x6) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[572] = 7 (0x7) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[573] = 8 (0x8) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[574] = 9 (0x9) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[575] = 459085000 (0x1B5D14C8) ---> Hadamard equivalent: [0.968873, -0.247559] (Probabilities: [0.938715, 0.061285])\n",
            "i_data[576] = 0 (0x0) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[577] = 1 (0x1) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[578] = 2 (0x2) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[579] = 3 (0x3) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[580] = 4 (0x4) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[581] = 5 (0x5) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[582] = 6 (0x6) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[583] = 7 (0x7) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[584] = 8 (0x8) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[585] = 9 (0x9) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[586] = 468085000 (0x1BE66908) ---> Hadamard equivalent: [0.971695, -0.236240] (Probabilities: [0.944191, 0.055809])\n",
            "i_data[587] = 0 (0x0) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[588] = 1 (0x1) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[589] = 2 (0x2) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[590] = 3 (0x3) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[591] = 4 (0x4) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[592] = 5 (0x5) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[593] = 6 (0x6) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[594] = 7 (0x7) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[595] = 8 (0x8) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[596] = 9 (0x9) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[597] = 477085000 (0x1C6FBD48) ---> Hadamard equivalent: [0.974403, -0.224807] (Probabilities: [0.949462, 0.050538])\n",
            "i_data[598] = 0 (0x0) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[599] = 1 (0x1) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[600] = 2 (0x2) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[601] = 3 (0x3) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[602] = 4 (0x4) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[603] = 5 (0x5) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[604] = 6 (0x6) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[605] = 7 (0x7) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[606] = 8 (0x8) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[607] = 9 (0x9) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[608] = 486085000 (0x1CF91188) ---> Hadamard equivalent: [0.976996, -0.213259] (Probabilities: [0.954521, 0.045479])\n",
            "i_data[609] = 0 (0x0) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[610] = 1 (0x1) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[611] = 2 (0x2) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[612] = 3 (0x3) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[613] = 4 (0x4) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[614] = 5 (0x5) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[615] = 6 (0x6) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[616] = 7 (0x7) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[617] = 8 (0x8) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[618] = 9 (0x9) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[619] = 495085000 (0x1D8265C8) ---> Hadamard equivalent: [0.979470, -0.201592] (Probabilities: [0.959361, 0.040639])\n",
            "i_data[620] = 0 (0x0) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[621] = 1 (0x1) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[622] = 2 (0x2) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[623] = 3 (0x3) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[624] = 4 (0x4) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[625] = 5 (0x5) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[626] = 6 (0x6) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[627] = 7 (0x7) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[628] = 8 (0x8) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[629] = 9 (0x9) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[630] = 504085000 (0x1E0BBA08) ---> Hadamard equivalent: [0.981822, -0.189804] (Probabilities: [0.963975, 0.036025])\n",
            "i_data[631] = 0 (0x0) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[632] = 1 (0x1) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[633] = 2 (0x2) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[634] = 3 (0x3) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[635] = 4 (0x4) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[636] = 5 (0x5) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[637] = 6 (0x6) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[638] = 7 (0x7) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[639] = 8 (0x8) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[640] = 9 (0x9) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[641] = 513085000 (0x1E950E48) ---> Hadamard equivalent: [0.984050, -0.177891] (Probabilities: [0.968355, 0.031645])\n",
            "i_data[642] = 0 (0x0) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[643] = 1 (0x1) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[644] = 2 (0x2) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[645] = 3 (0x3) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[646] = 4 (0x4) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[647] = 5 (0x5) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[648] = 6 (0x6) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[649] = 7 (0x7) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[650] = 8 (0x8) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[651] = 9 (0x9) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[652] = 522085000 (0x1F1E6288) ---> Hadamard equivalent: [0.986151, -0.165851] (Probabilities: [0.972493, 0.027507])\n",
            "i_data[653] = 0 (0x0) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[654] = 1 (0x1) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[655] = 2 (0x2) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[656] = 3 (0x3) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[657] = 4 (0x4) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[658] = 5 (0x5) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[659] = 6 (0x6) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[660] = 7 (0x7) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[661] = 8 (0x8) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[662] = 9 (0x9) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[663] = 531085000 (0x1FA7B6C8) ---> Hadamard equivalent: [0.988121, -0.153680] (Probabilities: [0.976382, 0.023618])\n",
            "i_data[664] = 0 (0x0) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[665] = 1 (0x1) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[666] = 2 (0x2) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[667] = 3 (0x3) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[668] = 4 (0x4) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[669] = 5 (0x5) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[670] = 6 (0x6) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[671] = 7 (0x7) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[672] = 8 (0x8) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[673] = 9 (0x9) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[674] = 540085000 (0x20310B08) ---> Hadamard equivalent: [0.989956, -0.141375] (Probabilities: [0.980013, 0.019987])\n",
            "i_data[675] = 0 (0x0) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[676] = 1 (0x1) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[677] = 2 (0x2) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[678] = 3 (0x3) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[679] = 4 (0x4) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[680] = 5 (0x5) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[681] = 6 (0x6) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[682] = 7 (0x7) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[683] = 8 (0x8) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[684] = 9 (0x9) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[685] = 549085000 (0x20BA5F48) ---> Hadamard equivalent: [0.991654, -0.128931] (Probabilities: [0.983377, 0.016623])\n",
            "i_data[686] = 0 (0x0) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[687] = 1 (0x1) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[688] = 2 (0x2) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[689] = 3 (0x3) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[690] = 4 (0x4) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[691] = 5 (0x5) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[692] = 6 (0x6) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[693] = 7 (0x7) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[694] = 8 (0x8) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[695] = 9 (0x9) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[696] = 558085000 (0x2143B388) ---> Hadamard equivalent: [0.993209, -0.116346] (Probabilities: [0.986464, 0.013536])\n",
            "i_data[697] = 0 (0x0) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[698] = 1 (0x1) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[699] = 2 (0x2) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[700] = 3 (0x3) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[701] = 4 (0x4) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[702] = 5 (0x5) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[703] = 6 (0x6) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[704] = 7 (0x7) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[705] = 8 (0x8) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[706] = 9 (0x9) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[707] = 567085000 (0x21CD07C8) ---> Hadamard equivalent: [0.994618, -0.103614] (Probabilities: [0.989264, 0.010736])\n",
            "i_data[708] = 0 (0x0) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[709] = 1 (0x1) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[710] = 2 (0x2) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[711] = 3 (0x3) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[712] = 4 (0x4) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[713] = 5 (0x5) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[714] = 6 (0x6) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[715] = 7 (0x7) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[716] = 8 (0x8) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[717] = 9 (0x9) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[718] = 576085000 (0x22565C08) ---> Hadamard equivalent: [0.995875, -0.090731] (Probabilities: [0.991768, 0.008232])\n",
            "i_data[719] = 0 (0x0) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[720] = 1 (0x1) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[721] = 2 (0x2) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[722] = 3 (0x3) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[723] = 4 (0x4) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[724] = 5 (0x5) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[725] = 6 (0x6) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[726] = 7 (0x7) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[727] = 8 (0x8) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[728] = 9 (0x9) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[729] = 585085000 (0x22DFB048) ---> Hadamard equivalent: [0.996977, -0.077692] (Probabilities: [0.993964, 0.006036])\n",
            "i_data[730] = 0 (0x0) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[731] = 1 (0x1) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[732] = 2 (0x2) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[733] = 3 (0x3) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[734] = 4 (0x4) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[735] = 5 (0x5) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[736] = 6 (0x6) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[737] = 7 (0x7) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[738] = 8 (0x8) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[739] = 9 (0x9) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[740] = 594085000 (0x23690488) ---> Hadamard equivalent: [0.997918, -0.064492] (Probabilities: [0.995841, 0.004159])\n",
            "i_data[741] = 0 (0x0) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[742] = 1 (0x1) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[743] = 2 (0x2) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[744] = 3 (0x3) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[745] = 4 (0x4) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[746] = 5 (0x5) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[747] = 6 (0x6) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[748] = 7 (0x7) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[749] = 8 (0x8) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[750] = 9 (0x9) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[751] = 603085000 (0x23F258C8) ---> Hadamard equivalent: [0.998692, -0.051125] (Probabilities: [0.997386, 0.002614])\n",
            "i_data[752] = 0 (0x0) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[753] = 1 (0x1) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[754] = 2 (0x2) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[755] = 3 (0x3) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[756] = 4 (0x4) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[757] = 5 (0x5) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[758] = 6 (0x6) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[759] = 7 (0x7) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[760] = 8 (0x8) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[761] = 9 (0x9) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[762] = 612085000 (0x247BAD08) ---> Hadamard equivalent: [0.999293, -0.037585] (Probabilities: [0.998587, 0.001413])\n",
            "i_data[763] = 0 (0x0) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[764] = 1 (0x1) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[765] = 2 (0x2) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[766] = 3 (0x3) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[767] = 4 (0x4) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[768] = 5 (0x5) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[769] = 6 (0x6) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[770] = 7 (0x7) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[771] = 8 (0x8) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[772] = 9 (0x9) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[773] = 621085000 (0x25050148) ---> Hadamard equivalent: [0.999715, -0.023866] (Probabilities: [0.999430, 0.000570])\n",
            "i_data[774] = 0 (0x0) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[775] = 1 (0x1) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[776] = 2 (0x2) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[777] = 3 (0x3) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[778] = 4 (0x4) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[779] = 5 (0x5) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[780] = 6 (0x6) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[781] = 7 (0x7) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[782] = 8 (0x8) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[783] = 9 (0x9) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[784] = 630085000 (0x258E5588) ---> Hadamard equivalent: [0.999950, -0.009961] (Probabilities: [0.999901, 0.000099])\n",
            "i_data[785] = 0 (0x0) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[786] = 1 (0x1) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[787] = 2 (0x2) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[788] = 3 (0x3) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[789] = 4 (0x4) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[790] = 5 (0x5) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[791] = 6 (0x6) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[792] = 7 (0x7) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[793] = 8 (0x8) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[794] = 9 (0x9) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[795] = 639085000 (0x2617A9C8) ---> Hadamard equivalent: [0.999991, 0.004139] (Probabilities: [0.999983, 0.000017])\n",
            "i_data[796] = 0 (0x0) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[797] = 1 (0x1) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[798] = 2 (0x2) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[799] = 3 (0x3) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[800] = 4 (0x4) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[801] = 5 (0x5) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[802] = 6 (0x6) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[803] = 7 (0x7) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[804] = 8 (0x8) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[805] = 9 (0x9) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[806] = 648085000 (0x26A0FE08) ---> Hadamard equivalent: [0.999830, 0.018441] (Probabilities: [0.999660, 0.000340])\n",
            "i_data[807] = 0 (0x0) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[808] = 1 (0x1) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[809] = 2 (0x2) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[810] = 3 (0x3) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[811] = 4 (0x4) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[812] = 5 (0x5) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[813] = 6 (0x6) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[814] = 7 (0x7) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[815] = 8 (0x8) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[816] = 9 (0x9) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[817] = 657085000 (0x272A5248) ---> Hadamard equivalent: [0.999457, 0.032955] (Probabilities: [0.998914, 0.001086])\n",
            "i_data[818] = 0 (0x0) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[819] = 1 (0x1) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[820] = 2 (0x2) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[821] = 3 (0x3) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[822] = 4 (0x4) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[823] = 5 (0x5) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[824] = 6 (0x6) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[825] = 7 (0x7) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[826] = 8 (0x8) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[827] = 9 (0x9) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[828] = 666085000 (0x27B3A688) ---> Hadamard equivalent: [0.998862, 0.047691] (Probabilities: [0.997726, 0.002274])\n",
            "i_data[829] = 0 (0x0) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[830] = 1 (0x1) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[831] = 2 (0x2) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[832] = 3 (0x3) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[833] = 4 (0x4) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[834] = 5 (0x5) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[835] = 6 (0x6) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[836] = 7 (0x7) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[837] = 8 (0x8) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[838] = 9 (0x9) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[839] = 675085000 (0x283CFAC8) ---> Hadamard equivalent: [0.998035, 0.062659] (Probabilities: [0.996074, 0.003926])\n",
            "i_data[840] = 0 (0x0) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[841] = 1 (0x1) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[842] = 2 (0x2) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[843] = 3 (0x3) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[844] = 4 (0x4) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[845] = 5 (0x5) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[846] = 6 (0x6) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[847] = 7 (0x7) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[848] = 8 (0x8) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[849] = 9 (0x9) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[850] = 684085000 (0x28C64F08) ---> Hadamard equivalent: [0.996963, 0.077871] (Probabilities: [0.993936, 0.006064])\n",
            "i_data[851] = 0 (0x0) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[852] = 1 (0x1) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[853] = 2 (0x2) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[854] = 3 (0x3) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[855] = 4 (0x4) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[856] = 5 (0x5) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[857] = 6 (0x6) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[858] = 7 (0x7) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[859] = 8 (0x8) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[860] = 9 (0x9) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[861] = 693085000 (0x294FA348) ---> Hadamard equivalent: [0.995634, 0.093341] (Probabilities: [0.991287, 0.008713])\n",
            "i_data[862] = 0 (0x0) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[863] = 1 (0x1) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[864] = 2 (0x2) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[865] = 3 (0x3) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[866] = 4 (0x4) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[867] = 5 (0x5) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[868] = 6 (0x6) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[869] = 7 (0x7) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[870] = 8 (0x8) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[871] = 9 (0x9) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[872] = 702085000 (0x29D8F788) ---> Hadamard equivalent: [0.994033, 0.109083] (Probabilities: [0.988101, 0.011899])\n",
            "i_data[873] = 0 (0x0) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[874] = 1 (0x1) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[875] = 2 (0x2) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[876] = 3 (0x3) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[877] = 4 (0x4) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[878] = 5 (0x5) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[879] = 6 (0x6) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[880] = 7 (0x7) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[881] = 8 (0x8) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[882] = 9 (0x9) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[883] = 711085000 (0x2A624BC8) ---> Hadamard equivalent: [0.992142, 0.125114] (Probabilities: [0.984346, 0.015654])\n",
            "i_data[884] = 0 (0x0) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[885] = 1 (0x1) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[886] = 2 (0x2) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[887] = 3 (0x3) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[888] = 4 (0x4) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[889] = 5 (0x5) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[890] = 6 (0x6) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[891] = 7 (0x7) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[892] = 8 (0x8) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[893] = 9 (0x9) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[894] = 720085000 (0x2AEBA008) ---> Hadamard equivalent: [0.989945, 0.141453] (Probabilities: [0.979991, 0.020009])\n",
            "i_data[895] = 0 (0x0) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[896] = 1 (0x1) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[897] = 2 (0x2) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[898] = 3 (0x3) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[899] = 4 (0x4) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[900] = 5 (0x5) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[901] = 6 (0x6) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[902] = 7 (0x7) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[903] = 8 (0x8) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[904] = 9 (0x9) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[905] = 729085000 (0x2B74F448) ---> Hadamard equivalent: [0.987420, 0.158118] (Probabilities: [0.974999, 0.025001])\n",
            "i_data[906] = 0 (0x0) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[907] = 1 (0x1) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[908] = 2 (0x2) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[909] = 3 (0x3) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[910] = 4 (0x4) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[911] = 5 (0x5) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[912] = 6 (0x6) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[913] = 7 (0x7) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[914] = 8 (0x8) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[915] = 9 (0x9) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[916] = 738085000 (0x2BFE4888) ---> Hadamard equivalent: [0.984544, 0.175135] (Probabilities: [0.969328, 0.030672])\n",
            "i_data[917] = 0 (0x0) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[918] = 1 (0x1) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[919] = 2 (0x2) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[920] = 3 (0x3) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[921] = 4 (0x4) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[922] = 5 (0x5) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[923] = 6 (0x6) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[924] = 7 (0x7) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[925] = 8 (0x8) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[926] = 9 (0x9) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[927] = 747085000 (0x2C879CC8) ---> Hadamard equivalent: [0.981291, 0.192529] (Probabilities: [0.962933, 0.037067])\n",
            "i_data[928] = 0 (0x0) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[929] = 1 (0x1) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[930] = 2 (0x2) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[931] = 3 (0x3) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[932] = 4 (0x4) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[933] = 5 (0x5) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[934] = 6 (0x6) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[935] = 7 (0x7) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[936] = 8 (0x8) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[937] = 9 (0x9) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[938] = 756085000 (0x2D10F108) ---> Hadamard equivalent: [0.977630, 0.210330] (Probabilities: [0.955761, 0.044239])\n",
            "i_data[939] = 0 (0x0) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[940] = 1 (0x1) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[941] = 2 (0x2) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[942] = 3 (0x3) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[943] = 4 (0x4) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[944] = 5 (0x5) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[945] = 6 (0x6) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[946] = 7 (0x7) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[947] = 8 (0x8) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[948] = 9 (0x9) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[949] = 765085000 (0x2D9A4548) ---> Hadamard equivalent: [0.973526, 0.228575] (Probabilities: [0.947753, 0.052247])\n",
            "i_data[950] = 0 (0x0) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[951] = 1 (0x1) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[952] = 2 (0x2) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[953] = 3 (0x3) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[954] = 4 (0x4) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[955] = 5 (0x5) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[956] = 6 (0x6) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[957] = 7 (0x7) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[958] = 8 (0x8) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[959] = 9 (0x9) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[960] = 774085000 (0x2E239988) ---> Hadamard equivalent: [0.968938, 0.247305] (Probabilities: [0.938840, 0.061160])\n",
            "i_data[961] = 0 (0x0) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[962] = 1 (0x1) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[963] = 2 (0x2) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[964] = 3 (0x3) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[965] = 4 (0x4) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[966] = 5 (0x5) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[967] = 6 (0x6) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[968] = 7 (0x7) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[969] = 8 (0x8) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[970] = 9 (0x9) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[971] = 783085000 (0x2EACEDC8) ---> Hadamard equivalent: [0.963816, 0.266567] (Probabilities: [0.928942, 0.071058])\n",
            "i_data[972] = 0 (0x0) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[973] = 1 (0x1) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[974] = 2 (0x2) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[975] = 3 (0x3) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[976] = 4 (0x4) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[977] = 5 (0x5) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[978] = 6 (0x6) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[979] = 7 (0x7) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[980] = 8 (0x8) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[981] = 9 (0x9) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[982] = 792085000 (0x2F364208) ---> Hadamard equivalent: [0.958104, 0.286420] (Probabilities: [0.917964, 0.082036])\n",
            "i_data[983] = 0 (0x0) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[984] = 1 (0x1) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[985] = 2 (0x2) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[986] = 3 (0x3) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[987] = 4 (0x4) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[988] = 5 (0x5) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[989] = 6 (0x6) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[990] = 7 (0x7) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[991] = 8 (0x8) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[992] = 9 (0x9) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[993] = 801085000 (0x2FBF9648) ---> Hadamard equivalent: [0.951731, 0.306934] (Probabilities: [0.905792, 0.094208])\n",
            "i_data[994] = 0 (0x0) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[995] = 1 (0x1) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[996] = 2 (0x2) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[997] = 3 (0x3) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[998] = 4 (0x4) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[999] = 5 (0x5) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[1000] = 6 (0x6) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[1001] = 7 (0x7) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[1002] = 8 (0x8) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[1003] = 9 (0x9) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[1004] = 810085000 (0x3048EA88) ---> Hadamard equivalent: [0.944610, 0.328196] (Probabilities: [0.892287, 0.107713])\n",
            "i_data[1005] = 0 (0x0) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[1006] = 1 (0x1) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[1007] = 2 (0x2) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[1008] = 3 (0x3) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[1009] = 4 (0x4) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[1010] = 5 (0x5) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[1011] = 6 (0x6) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[1012] = 7 (0x7) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[1013] = 8 (0x8) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[1014] = 9 (0x9) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[1015] = 819085000 (0x30D23EC8) ---> Hadamard equivalent: [0.936632, 0.350314] (Probabilities: [0.877280, 0.122720])\n",
            "i_data[1016] = 0 (0x0) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[1017] = 1 (0x1) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[1018] = 2 (0x2) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[1019] = 3 (0x3) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[1020] = 4 (0x4) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[1021] = 5 (0x5) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[1022] = 6 (0x6) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[1023] = 7 (0x7) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[1024] = 8 (0x8) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[1025] = 9 (0x9) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[1026] = 828085000 (0x315B9308) ---> Hadamard equivalent: [0.927659, 0.373428] (Probabilities: [0.860552, 0.139448])\n",
            "i_data[1027] = 0 (0x0) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[1028] = 1 (0x1) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[1029] = 2 (0x2) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[1030] = 3 (0x3) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[1031] = 4 (0x4) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[1032] = 5 (0x5) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[1033] = 6 (0x6) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[1034] = 7 (0x7) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[1035] = 8 (0x8) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[1036] = 9 (0x9) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[1037] = 837085000 (0x31E4E748) ---> Hadamard equivalent: [0.917506, 0.397722] (Probabilities: [0.841817, 0.158183])\n",
            "i_data[1038] = 0 (0x0) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[1039] = 1 (0x1) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[1040] = 2 (0x2) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[1041] = 3 (0x3) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[1042] = 4 (0x4) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[1043] = 5 (0x5) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[1044] = 6 (0x6) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[1045] = 7 (0x7) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[1046] = 8 (0x8) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[1047] = 9 (0x9) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[1048] = 846085000 (0x326E3B88) ---> Hadamard equivalent: [0.905920, 0.423449] (Probabilities: [0.820691, 0.179309])\n",
            "i_data[1049] = 0 (0x0) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[1050] = 1 (0x1) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[1051] = 2 (0x2) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[1052] = 3 (0x3) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[1053] = 4 (0x4) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[1054] = 5 (0x5) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[1055] = 6 (0x6) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[1056] = 7 (0x7) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[1057] = 8 (0x8) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[1058] = 9 (0x9) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[1059] = 855085000 (0x32F78FC8) ---> Hadamard equivalent: [0.892539, 0.450971] (Probabilities: [0.796625, 0.203375])\n",
            "i_data[1060] = 0 (0x0) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[1061] = 1 (0x1) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[1062] = 2 (0x2) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[1063] = 3 (0x3) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[1064] = 4 (0x4) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[1065] = 5 (0x5) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[1066] = 6 (0x6) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[1067] = 7 (0x7) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[1068] = 8 (0x8) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[1069] = 9 (0x9) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[1070] = 864085000 (0x3380E408) ---> Hadamard equivalent: [0.876806, 0.480844] (Probabilities: [0.768789, 0.231211])\n",
            "i_data[1071] = 0 (0x0) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[1072] = 1 (0x1) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[1073] = 2 (0x2) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[1074] = 3 (0x3) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[1075] = 4 (0x4) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[1076] = 5 (0x5) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[1077] = 6 (0x6) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[1078] = 7 (0x7) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[1079] = 8 (0x8) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[1080] = 9 (0x9) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[1081] = 873085000 (0x340A3848) ---> Hadamard equivalent: [0.857789, 0.514002] (Probabilities: [0.735801, 0.264199])\n",
            "i_data[1082] = 0 (0x0) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[1083] = 1 (0x1) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[1084] = 2 (0x2) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[1085] = 3 (0x3) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[1086] = 4 (0x4) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[1087] = 5 (0x5) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[1088] = 6 (0x6) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[1089] = 7 (0x7) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[1090] = 8 (0x8) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[1091] = 9 (0x9) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[1092] = 882085000 (0x34938C88) ---> Hadamard equivalent: [0.833672, 0.552260] (Probabilities: [0.695009, 0.304991])\n",
            "i_data[1093] = 0 (0x0) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[1094] = 1 (0x1) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[1095] = 2 (0x2) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[1096] = 3 (0x3) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[1097] = 4 (0x4) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[1098] = 5 (0x5) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[1099] = 6 (0x6) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[1100] = 7 (0x7) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[1101] = 8 (0x8) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[1102] = 9 (0x9) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[1103] = 891085000 (0x351CE0C8) ---> Hadamard equivalent: [0.799781, 0.600291] (Probabilities: [0.639650, 0.360350])\n",
            "i_data[1104] = 0 (0x0) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[1105] = 1 (0x1) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[1106] = 2 (0x2) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[1107] = 3 (0x3) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[1108] = 4 (0x4) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[1109] = 5 (0x5) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[1110] = 6 (0x6) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[1111] = 7 (0x7) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[1112] = 8 (0x8) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[1113] = 9 (0x9) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[1114] = 900085000 (0x35A63508) ---> Hadamard equivalent: [0.707107, 0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[1115] = 0 (0x0) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[1116] = 1 (0x1) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[1117] = 2 (0x2) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[1118] = 3 (0x3) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[1119] = 4 (0x4) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[1120] = 5 (0x5) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[1121] = 6 (0x6) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[1122] = 7 (0x7) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[1123] = 8 (0x8) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "i_data[1124] = 9 (0x9) ---> Hadamard equivalent: [0.707107, -0.707107] (Probabilities: [0.500000, 0.500000])\n",
            "\n",
            "Example row:\n",
            "(index, frame_val, a, b, out0, out1, p0, p1)\n",
            " (0, 9085000, np.float64(0.010093491170278362), np.float64(0.9999490594205265), np.float64(0.7142079368097146), np.float64(-0.6999335847050138), np.float64(0.5100929770019893), np.float64(0.4899070229980107))\n",
            "\n",
            "Saved Verilog lookup table to: max_finder frame (1)_hadamard_lookup.mem\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_4d720d80-d584-4910-9654-a5c39cc16226\", \"max_finder frame (1)_hadamard_lookup.mem\", 80120)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "X1dwH36r1cRu"
      },
      "id": "X1dwH36r1cRu"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}